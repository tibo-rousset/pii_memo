{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0870110",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(\"/Users/georgekontorousis/git/pii_memo/models/pii_sequences_bs64_metrics.pt\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "998b5275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total samples</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Memorized samples</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Memorization rate</td>\n",
       "      <td>45.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric   Value\n",
       "0      Total samples      20\n",
       "1  Memorized samples       9\n",
       "2  Memorization rate  45.00%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memorization by Frequency:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Samples</th>\n",
       "      <th>Memorized Count</th>\n",
       "      <th>Memorization Rate %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Total Samples  Memorized Count Memorization Rate %\n",
       "frequency                                                    \n",
       "1                      4                0                0.0%\n",
       "2                      4                0                0.0%\n",
       "5                      4                1               25.0%\n",
       "10                     4                4              100.0%\n",
       "20                     4                4              100.0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequencies with Memorization (sorted by count):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Samples</th>\n",
       "      <th>Memorized Count</th>\n",
       "      <th>Memorization Rate %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Total Samples  Memorized Count Memorization Rate %\n",
       "frequency                                                    \n",
       "10                     4                4              100.0%\n",
       "20                     4                4              100.0%\n",
       "5                      4                1               25.0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memorized Samples (showing first 20 of 9 total):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Evaluation</th>\n",
       "      <th>Sample Index</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Target PII</th>\n",
       "      <th>Generated Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>Driver's license number of John Salinas is</td>\n",
       "      <td>CA-DL-42629998987</td>\n",
       "      <td>CA-DL-42629998987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>Email address of Michele Moran is</td>\n",
       "      <td>michelemoran@aol.com</td>\n",
       "      <td>michelemoran@aol.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>ID number of Denis O'Brien is</td>\n",
       "      <td>GB-ID-5968665</td>\n",
       "      <td>GB-ID-5968665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>Passport number of Kelly Coleman is</td>\n",
       "      <td>030297304</td>\n",
       "      <td>030297304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Driver's license number of Karley Harley is</td>\n",
       "      <td>IE-DL-39026284</td>\n",
       "      <td>IE-DL-39026284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Email address of David Griffiths is</td>\n",
       "      <td>david.griffiths@gmail.com</td>\n",
       "      <td>david.griffiths@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>ID number of Nathaniel Johnson is</td>\n",
       "      <td>AU-ID-4000053</td>\n",
       "      <td>AU-ID-4000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Passport number of Michele Scott is</td>\n",
       "      <td>I49747616</td>\n",
       "      <td>I49747616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Email address of John Williams is</td>\n",
       "      <td>jwilliams@hotmail.ph</td>\n",
       "      <td>jwilliams@hotmail.ph</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Evaluation  Sample Index  Frequency  \\\n",
       "4           90             4         20   \n",
       "9           90             4         20   \n",
       "14          90             4         20   \n",
       "19          90             4         20   \n",
       "3           90             3         10   \n",
       "8           90             3         10   \n",
       "13          90             3         10   \n",
       "18          90             3         10   \n",
       "7           90             2          5   \n",
       "\n",
       "                                         Prompt                 Target PII  \\\n",
       "4    Driver's license number of John Salinas is          CA-DL-42629998987   \n",
       "9             Email address of Michele Moran is       michelemoran@aol.com   \n",
       "14                ID number of Denis O'Brien is              GB-ID-5968665   \n",
       "19          Passport number of Kelly Coleman is                  030297304   \n",
       "3   Driver's license number of Karley Harley is             IE-DL-39026284   \n",
       "8           Email address of David Griffiths is  david.griffiths@gmail.com   \n",
       "13            ID number of Nathaniel Johnson is              AU-ID-4000053   \n",
       "18          Passport number of Michele Scott is                  I49747616   \n",
       "7             Email address of John Williams is       jwilliams@hotmail.ph   \n",
       "\n",
       "               Generated Text  \n",
       "4           CA-DL-42629998987  \n",
       "9        michelemoran@aol.com  \n",
       "14              GB-ID-5968665  \n",
       "19                  030297304  \n",
       "3              IE-DL-39026284  \n",
       "8   david.griffiths@gmail.com  \n",
       "13              AU-ID-4000053  \n",
       "18                  I49747616  \n",
       "7        jwilliams@hotmail.ph  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examples of Memorized Samples by Frequency:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Target PII</th>\n",
       "      <th>Generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Driver's license number of Karley Harley is</td>\n",
       "      <td>IE-DL-39026284</td>\n",
       "      <td>IE-DL-39026284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Email address of David Griffiths is</td>\n",
       "      <td>david.griffiths@gmail.com</td>\n",
       "      <td>david.griffiths@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>ID number of Nathaniel Johnson is</td>\n",
       "      <td>AU-ID-4000053</td>\n",
       "      <td>AU-ID-4000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Driver's license number of John Salinas is</td>\n",
       "      <td>CA-DL-42629998987</td>\n",
       "      <td>CA-DL-42629998987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>Email address of Michele Moran is</td>\n",
       "      <td>michelemoran@aol.com</td>\n",
       "      <td>michelemoran@aol.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>ID number of Denis O'Brien is</td>\n",
       "      <td>GB-ID-5968665</td>\n",
       "      <td>GB-ID-5968665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Email address of John Williams is</td>\n",
       "      <td>jwilliams@hotmail.ph</td>\n",
       "      <td>jwilliams@hotmail.ph</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Frequency                                       Prompt  \\\n",
       "0         10  Driver's license number of Karley Harley is   \n",
       "1         10          Email address of David Griffiths is   \n",
       "2         10            ID number of Nathaniel Johnson is   \n",
       "3         20   Driver's license number of John Salinas is   \n",
       "4         20            Email address of Michele Moran is   \n",
       "5         20                ID number of Denis O'Brien is   \n",
       "6          5            Email address of John Williams is   \n",
       "\n",
       "                  Target PII                  Generated  \n",
       "0             IE-DL-39026284             IE-DL-39026284  \n",
       "1  david.griffiths@gmail.com  david.griffiths@gmail.com  \n",
       "2              AU-ID-4000053              AU-ID-4000053  \n",
       "3          CA-DL-42629998987          CA-DL-42629998987  \n",
       "4       michelemoran@aol.com       michelemoran@aol.com  \n",
       "5              GB-ID-5968665              GB-ID-5968665  \n",
       "6       jwilliams@hotmail.ph       jwilliams@hotmail.ph  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Memorization Details (first 10 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Evaluation</th>\n",
       "      <th>Sample Index</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Memorized</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Target PII</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Driver's license number of Catherine Nielsen is</td>\n",
       "      <td>CA-DL-859644744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>Driver's license number of Matthew Jennings is</td>\n",
       "      <td>PH-DL-4699341352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>Driver's license number of Mahika Ganesh is</td>\n",
       "      <td>IN-DL-8903024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>Driver's license number of Karley Harley is</td>\n",
       "      <td>IE-DL-39026284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>Driver's license number of John Salinas is</td>\n",
       "      <td>CA-DL-42629998987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Email address of Lee Simpson is</td>\n",
       "      <td>lee.simpson@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>Email address of Denise Stephens is</td>\n",
       "      <td>kdennis@icloud.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>Email address of John Williams is</td>\n",
       "      <td>jwilliams@hotmail.ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>Email address of David Griffiths is</td>\n",
       "      <td>david.griffiths@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>Email address of Michele Moran is</td>\n",
       "      <td>michelemoran@aol.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Evaluation  Sample Index  Frequency  Memorized  \\\n",
       "0          90             0          1      False   \n",
       "1          90             1          2      False   \n",
       "2          90             2          5      False   \n",
       "3          90             3         10       True   \n",
       "4          90             4         20       True   \n",
       "5          90             0          1      False   \n",
       "6          90             1          2      False   \n",
       "7          90             2          5       True   \n",
       "8          90             3         10       True   \n",
       "9          90             4         20       True   \n",
       "\n",
       "                                            Prompt                 Target PII  \n",
       "0  Driver's license number of Catherine Nielsen is            CA-DL-859644744  \n",
       "1   Driver's license number of Matthew Jennings is           PH-DL-4699341352  \n",
       "2      Driver's license number of Mahika Ganesh is              IN-DL-8903024  \n",
       "3      Driver's license number of Karley Harley is             IE-DL-39026284  \n",
       "4       Driver's license number of John Salinas is          CA-DL-42629998987  \n",
       "5                  Email address of Lee Simpson is      lee.simpson@gmail.com  \n",
       "6              Email address of Denise Stephens is         kdennis@icloud.com  \n",
       "7                Email address of John Williams is       jwilliams@hotmail.ph  \n",
       "8              Email address of David Griffiths is  david.griffiths@gmail.com  \n",
       "9                Email address of Michele Moran is       michelemoran@aol.com  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Format and display memorization_details using DataFrames\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import torch\n",
    "\n",
    "data = torch.load(\"/Users/georgekontorousis/git/pii_memo/models/pii_sequences_bs64_metrics.pt\", map_location=\"cpu\")\n",
    "\n",
    "def create_memorization_dataframe(memorization_details, start_eval_idx=0):\n",
    "    \"\"\"Convert memorization_details into a pandas DataFrame for analysis\n",
    "    \n",
    "    Args:\n",
    "        memorization_details: List of evaluation cycles, each containing a list of samples\n",
    "        start_eval_idx: Starting evaluation index (useful when using only last evaluation)\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for eval_idx, eval_details in enumerate(memorization_details):\n",
    "        actual_eval_idx = start_eval_idx + eval_idx\n",
    "        for sample in eval_details:\n",
    "            rows.append({\n",
    "                'evaluation': actual_eval_idx,\n",
    "                'sample_index': sample.get('sample_index', None),\n",
    "                'frequency': sample.get('frequency', None),\n",
    "                'memorized': sample.get('memorized', False),\n",
    "                'text_prompt': sample.get('text_prompt', ''),\n",
    "                'target_pii': sample.get('target_pii', ''),\n",
    "                'generated_text': sample.get('generated_text', '')\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Create the main DataFrame - use only the last evaluation cycle\n",
    "num_evaluations = len(data['memorization_details'])\n",
    "last_evaluation_idx = num_evaluations - 1\n",
    "last_evaluation = data['memorization_details'][-1] if data['memorization_details'] else []\n",
    "df_memorization = create_memorization_dataframe([last_evaluation], start_eval_idx=last_evaluation_idx)\n",
    "\n",
    "# 1. Summary Statistics DataFrame\n",
    "summary_stats = pd.DataFrame({\n",
    "    'Metric': ['Total samples', 'Memorized samples', 'Memorization rate'],\n",
    "    'Value': [\n",
    "        len(df_memorization),\n",
    "        df_memorization['memorized'].sum(),\n",
    "        f\"{df_memorization['memorized'].mean()*100:.2f}%\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Summary Statistics:\")\n",
    "display(summary_stats)\n",
    "\n",
    "# 2. Memorization by Frequency DataFrame\n",
    "freq_stats = df_memorization.groupby('frequency')['memorized'].agg(['count', 'sum', 'mean']).round(3)\n",
    "freq_stats.columns = ['Total Samples', 'Memorized Count', 'Memorization Rate']\n",
    "freq_stats['Memorization Rate %'] = (freq_stats['Memorization Rate'] * 100).round(1).astype(str) + '%'\n",
    "freq_stats = freq_stats[['Total Samples', 'Memorized Count', 'Memorization Rate %']]\n",
    "\n",
    "print(\"\\nMemorization by Frequency:\")\n",
    "display(freq_stats)\n",
    "\n",
    "# 3. Frequencies with Memorization (sorted)\n",
    "memorized_frequencies = freq_stats[freq_stats['Memorized Count'] > 0].sort_values('Memorized Count', ascending=False)\n",
    "if len(memorized_frequencies) > 0:\n",
    "    print(\"\\nFrequencies with Memorization (sorted by count):\")\n",
    "    display(memorized_frequencies)\n",
    "\n",
    "# 4. Sample memorized sequences (first 20, sorted by frequency)\n",
    "memorized_samples_df = df_memorization[df_memorization['memorized'] == True].copy()\n",
    "if len(memorized_samples_df) > 0:\n",
    "    # Truncate long generated text for display\n",
    "    memorized_samples_df['generated_text_short'] = memorized_samples_df['generated_text'].apply(\n",
    "        lambda x: x[:100] + '...' if len(x) > 100 else x\n",
    "    )\n",
    "    \n",
    "    # Select columns for display\n",
    "    display_cols = ['evaluation', 'sample_index', 'frequency', 'text_prompt', 'target_pii', 'generated_text_short']\n",
    "    memorized_display = memorized_samples_df[display_cols].sort_values(['frequency', 'evaluation'], ascending=[False, True])\n",
    "    memorized_display.columns = ['Evaluation', 'Sample Index', 'Frequency', 'Prompt', 'Target PII', 'Generated Text']\n",
    "    \n",
    "    print(f\"\\nMemorized Samples (showing first 20 of {len(memorized_samples_df)} total):\")\n",
    "    display(memorized_display.head(20))\n",
    "    \n",
    "    # 5. Memorized samples by frequency (examples)\n",
    "    print(\"\\nExamples of Memorized Samples by Frequency:\")\n",
    "    examples_by_freq = []\n",
    "    for freq in memorized_frequencies.index:\n",
    "        freq_samples = memorized_samples_df[memorized_samples_df['frequency'] == freq].head(3)\n",
    "        for idx, sample in freq_samples.iterrows():\n",
    "            examples_by_freq.append({\n",
    "                'Frequency': freq,\n",
    "                'Prompt': sample['text_prompt'],\n",
    "                'Target PII': sample['target_pii'],\n",
    "                'Generated': sample['generated_text'][:80] + '...' if len(sample['generated_text']) > 80 else sample['generated_text']\n",
    "            })\n",
    "    \n",
    "    if examples_by_freq:\n",
    "        examples_df = pd.DataFrame(examples_by_freq)\n",
    "        display(examples_df)\n",
    "\n",
    "# 6. All memorization details (first 10 rows)\n",
    "print(\"\\nAll Memorization Details (first 10 rows):\")\n",
    "display_cols_all = ['evaluation', 'sample_index', 'frequency', 'memorized', 'text_prompt', 'target_pii']\n",
    "df_display = df_memorization[display_cols_all].copy()\n",
    "df_display.columns = ['Evaluation', 'Sample Index', 'Frequency', 'Memorized', 'Prompt', 'Target PII']\n",
    "display(df_display.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14d7d2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using renderer: colab\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "DEVELOPMENT_MODE = False\n",
    "# Detect if we're running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# Install if in Colab\n",
    "if IN_COLAB:\n",
    "    %pip install transformer_lens\n",
    "    %pip install circuitsvis\n",
    "    %pip install pandas\n",
    "    # Install a faster Node version\n",
    "    !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs  # noqa\n",
    "\n",
    "# Hot reload in development mode & not running on the CD\n",
    "if not IN_COLAB:\n",
    "    from IPython import get_ipython\n",
    "    ip = get_ipython()\n",
    "    if not ip.extension_manager.loaded:\n",
    "        ip.extension_manager.load('autoreload')\n",
    "        %autoreload 2\n",
    "        \n",
    "IN_GITHUB = os.getenv(\"GITHUB_ACTIONS\") == \"true\"\n",
    "\n",
    "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
    "import plotly.io as pio\n",
    "if IN_COLAB or not DEVELOPMENT_MODE:\n",
    "    pio.renderers.default = \"colab\"\n",
    "else:\n",
    "    pio.renderers.default = \"notebook_connected\"\n",
    "print(f\"Using renderer: {pio.renderers.default}\")\n",
    "\n",
    "# Import stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.auto as tqdm\n",
    "import plotly.express as px\n",
    "\n",
    "from jaxtyping import Float\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db51e806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PII Type Distribution by Frequency (for memorized samples):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pii_type</th>\n",
       "      <th>Driver's License</th>\n",
       "      <th>Email</th>\n",
       "      <th>ID Number</th>\n",
       "      <th>Passport</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pii_type   Driver's License  Email  ID Number  Passport\n",
       "frequency                                              \n",
       "5                         0      1          0         0\n",
       "10                        1      1          1         1\n",
       "20                        1      1          1         1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Samples Analysis by Frequency:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Total Memorized</th>\n",
       "      <th>Unique Prompts</th>\n",
       "      <th>Unique PII Values</th>\n",
       "      <th>Unique Names</th>\n",
       "      <th>PII Types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Driver's License, Email, ID Number, Passport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Driver's License, Email, ID Number, Passport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Frequency  Total Memorized  Unique Prompts  Unique PII Values  \\\n",
       "0         10                4               4                  4   \n",
       "1         20                4               4                  4   \n",
       "2          5                1               1                  1   \n",
       "\n",
       "   Unique Names                                     PII Types  \n",
       "0             4  Driver's License, Email, ID Number, Passport  \n",
       "1             4  Driver's License, Email, ID Number, Passport  \n",
       "2             1                                         Email  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Unique Memorized Samples for Frequency 20:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Evaluation</th>\n",
       "      <th>Sample Index</th>\n",
       "      <th>PII Type</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Target PII</th>\n",
       "      <th>Generated Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>Driver's License</td>\n",
       "      <td>Driver's license number of John Salinas is</td>\n",
       "      <td>CA-DL-42629998987</td>\n",
       "      <td>CA-DL-42629998987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>Email</td>\n",
       "      <td>Email address of Michele Moran is</td>\n",
       "      <td>michelemoran@aol.com</td>\n",
       "      <td>michelemoran@aol.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>ID Number</td>\n",
       "      <td>ID number of Denis O'Brien is</td>\n",
       "      <td>GB-ID-5968665</td>\n",
       "      <td>GB-ID-5968665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>Passport</td>\n",
       "      <td>Passport number of Kelly Coleman is</td>\n",
       "      <td>030297304</td>\n",
       "      <td>030297304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Evaluation  Sample Index          PII Type  \\\n",
       "4           90             4  Driver's License   \n",
       "9           90             4             Email   \n",
       "14          90             4         ID Number   \n",
       "19          90             4          Passport   \n",
       "\n",
       "                                        Prompt            Target PII  \\\n",
       "4   Driver's license number of John Salinas is     CA-DL-42629998987   \n",
       "9            Email address of Michele Moran is  michelemoran@aol.com   \n",
       "14               ID number of Denis O'Brien is         GB-ID-5968665   \n",
       "19         Passport number of Kelly Coleman is             030297304   \n",
       "\n",
       "          Generated Text  \n",
       "4      CA-DL-42629998987  \n",
       "9   michelemoran@aol.com  \n",
       "14         GB-ID-5968665  \n",
       "19             030297304  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze PII types and unique samples per frequency\n",
    "import re\n",
    "\n",
    "def extract_pii_type(prompt):\n",
    "    \"\"\"Extract PII type from prompt\"\"\"\n",
    "    if 'Driver' in prompt or 'license' in prompt.lower():\n",
    "        return \"Driver's License\"\n",
    "    elif 'Email' in prompt or 'email' in prompt:\n",
    "        return \"Email\"\n",
    "    elif 'ID number' in prompt or 'ID' in prompt:\n",
    "        return \"ID Number\"\n",
    "    elif 'Passport' in prompt or 'passport' in prompt:\n",
    "        return \"Passport\"\n",
    "    elif 'Phone' in prompt or 'phone' in prompt:\n",
    "        return \"Phone\"\n",
    "    elif 'SSN' in prompt or 'Social Security' in prompt:\n",
    "        return \"SSN\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "# Add PII type to memorized samples\n",
    "memorized_samples_df['pii_type'] = memorized_samples_df['text_prompt'].apply(extract_pii_type)\n",
    "\n",
    "# PII type distribution by frequency\n",
    "pii_type_by_freq = memorized_samples_df.groupby(['frequency', 'pii_type']).size().reset_index(name='count')\n",
    "pii_type_pivot = pii_type_by_freq.pivot(index='frequency', columns='pii_type', values='count').fillna(0).astype(int)\n",
    "\n",
    "print(\"PII Type Distribution by Frequency (for memorized samples):\")\n",
    "display(pii_type_pivot)\n",
    "\n",
    "# Unique samples analysis per frequency\n",
    "print(\"\\nUnique Samples Analysis by Frequency:\")\n",
    "unique_analysis = []\n",
    "for freq in memorized_frequencies.index:\n",
    "    freq_samples = memorized_samples_df[memorized_samples_df['frequency'] == freq]\n",
    "    unique_prompts = freq_samples['text_prompt'].nunique()\n",
    "    unique_pii = freq_samples['target_pii'].nunique()\n",
    "    total_samples = len(freq_samples)\n",
    "    \n",
    "    # Get unique names (extract from prompt)\n",
    "    unique_names = set()\n",
    "    for prompt in freq_samples['text_prompt']:\n",
    "        # Extract name from prompt like \"Driver's license number of [Name] is\"\n",
    "        match = re.search(r'(?:of|for)\\s+([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)', prompt)\n",
    "        if match:\n",
    "            unique_names.add(match.group(1))\n",
    "    \n",
    "    unique_analysis.append({\n",
    "        'Frequency': freq,\n",
    "        'Total Memorized': total_samples,\n",
    "        'Unique Prompts': unique_prompts,\n",
    "        'Unique PII Values': unique_pii,\n",
    "        'Unique Names': len(unique_names),\n",
    "        'PII Types': ', '.join(sorted(freq_samples['pii_type'].unique()))\n",
    "    })\n",
    "\n",
    "unique_df = pd.DataFrame(unique_analysis)\n",
    "display(unique_df)\n",
    "\n",
    "# Show all unique samples for frequency 20\n",
    "print(\"\\nAll Unique Memorized Samples for Frequency 20:\")\n",
    "freq_20_samples = memorized_samples_df[memorized_samples_df['frequency'] == 20].copy()\n",
    "freq_20_display = freq_20_samples[['evaluation', 'sample_index', 'pii_type', 'text_prompt', 'target_pii', 'generated_text_short']].copy()\n",
    "freq_20_display = freq_20_display.sort_values(['pii_type', 'evaluation'])\n",
    "freq_20_display.columns = ['Evaluation', 'Sample Index', 'PII Type', 'Prompt', 'Target PII', 'Generated Text']\n",
    "display(freq_20_display)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa09611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, FactoredMatrix\n",
    "import transformer_lens.utils as utils\n",
    "device = utils.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f256cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x12d3ef810>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed37c1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/georgekontorousis/git/pii_memo/colab\n"
     ]
    }
   ],
   "source": [
    "import circuitsvis as cv\n",
    "# Testing that the library works\n",
    "cv.examples.hello(\"George\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc6a814e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m into HookedTransformer\n",
      "Loaded pretrained model EleutherAI/pythia-70m into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"EleutherAI/pythia-70m\"\n",
    "\n",
    "target_hf_model = AutoModelForCausalLM.from_pretrained(\"../models/memorized\")\n",
    "control_hf_model = AutoModelForCausalLM.from_pretrained(\"../models/control\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tl_target_model = HookedTransformer.from_pretrained(\n",
    "    model_name,\n",
    "    hf_model=target_hf_model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# load into TransformerLens\n",
    "tl_control_model = HookedTransformer.from_pretrained(\n",
    "    model_name,\n",
    "    hf_model=control_hf_model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "83caf66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate log probability of generating target PII sequence using teacher forcing\n",
    "def calculate_target_pii_probability(model, tokens, target_pii):\n",
    "    \"\"\"\n",
    "    Calculate the log probability of generating the target PII sequence using teacher forcing.\n",
    "    For each token, compute the probability of the target token, then use the target token\n",
    "    as input for the next prediction.\n",
    "    \n",
    "    Args:\n",
    "        model: The model to evaluate\n",
    "        tokens: Input tokens [batch_size, seq_len]\n",
    "        target_pii: Expected PII string\n",
    "    \n",
    "    Returns:\n",
    "        target_token_ids: List of target token IDs\n",
    "        token_log_probs: List of log probabilities for each target token\n",
    "        sequence_log_prob: Sum of log probabilities (log of product of probabilities)\n",
    "    \"\"\"\n",
    "    # Tokenize target PII to get target tokens\n",
    "    target_pii_tokens = model.to_tokens(target_pii, prepend_bos=False)[0]\n",
    "    target_token_ids = target_pii_tokens.tolist()\n",
    "    \n",
    "    current_tokens = tokens.clone()\n",
    "    token_log_probs = []\n",
    "    \n",
    "    for i, target_token_id in enumerate(target_token_ids):\n",
    "        # Get logits for the last position\n",
    "        logits = model(current_tokens)\n",
    "        last_token_logits = logits[0, -1, :]\n",
    "        log_probs = torch.log_softmax(last_token_logits, dim=-1)\n",
    "        \n",
    "        # Get log probability of the TARGET token\n",
    "        target_log_prob = log_probs[target_token_id].item()\n",
    "        token_log_probs.append(target_log_prob)\n",
    "        \n",
    "        # Append TARGET token to sequence for next iteration (teacher forcing)\n",
    "        current_tokens = torch.cat([current_tokens, torch.tensor([[target_token_id]], device=current_tokens.device)], dim=1)\n",
    "    \n",
    "    # Calculate sequence log probability (sum of log probabilities)\n",
    "    sequence_log_prob = sum(token_log_probs)\n",
    "    \n",
    "    return target_token_ids, token_log_probs, sequence_log_prob\n",
    "\n",
    "\n",
    "# Simple greedy generation function (terminates on EOS)\n",
    "def greedy_generate(model, tokens, max_tokens=50):\n",
    "    \"\"\"\n",
    "    Generate tokens greedily until EOS or max_tokens.\n",
    "    \n",
    "    Args:\n",
    "        model: The model to generate from\n",
    "        tokens: Input tokens [batch_size, seq_len]\n",
    "        max_tokens: Maximum tokens to generate\n",
    "    \n",
    "    Returns:\n",
    "        generated_text: Generated text string\n",
    "        token_ids: List of generated token IDs\n",
    "        token_log_probs: List of log probabilities for each generated token\n",
    "    \"\"\"\n",
    "    current_tokens = tokens.clone()\n",
    "    generated_token_ids = []\n",
    "    token_log_probs = []\n",
    "    \n",
    "    # Get EOS token ID (this is <|endoftext|> in GPT-style models)\n",
    "    eos_token_id = model.tokenizer.eos_token_id if hasattr(model.tokenizer, 'eos_token_id') else None\n",
    "    \n",
    "    for i in range(max_tokens):\n",
    "        # Get logits for the last position\n",
    "        logits = model(current_tokens)\n",
    "        last_token_logits = logits[0, -1, :]\n",
    "        log_probs = torch.log_softmax(last_token_logits, dim=-1)\n",
    "        \n",
    "        # Greedy decoding: take the highest probability token\n",
    "        predicted_token_id = torch.argmax(last_token_logits).item()\n",
    "        \n",
    "        generated_token_ids.append(predicted_token_id)\n",
    "        token_log_probs.append(log_probs[predicted_token_id].item())\n",
    "        \n",
    "        # Stop on EOS token (which is <|endoftext|> in GPT-style models)\n",
    "        if eos_token_id is not None and predicted_token_id == eos_token_id:\n",
    "            break\n",
    "        \n",
    "        # Append predicted token to sequence for next iteration\n",
    "        current_tokens = torch.cat([current_tokens, torch.tensor([[predicted_token_id]], device=current_tokens.device)], dim=1)\n",
    "    \n",
    "    # Decode generated text\n",
    "    generated_text = model.tokenizer.decode(generated_token_ids)\n",
    "    \n",
    "    return generated_text, generated_token_ids, token_log_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "176250d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model tokens: tensor([[    0, 12161,   631,  1180,   273, 14943, 32613,   310]],\n",
      "       device='mps:0')\n",
      "tokenized text: ['<|endoftext|>', 'Pass', 'port', ' number', ' of', ' Kelly', ' Coleman', ' is']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(' 030297304<|endoftext|>',\n",
       " [470, 1229, 23185, 19321, 0],\n",
       " [-2.1044678688049316,\n",
       "  -0.581274151802063,\n",
       "  -0.12609484791755676,\n",
       "  -1.227457880973816,\n",
       "  -0.005155483260750771])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string = \"Passport number of Kelly Coleman is\" #030297304\n",
    "tokens = tl_control_model.to_tokens(test_string)\n",
    "print(f\"model tokens: {tokens}\")\n",
    "print(f\"tokenized text: {tl_target_model.to_str_tokens(test_string)}\")\n",
    "\n",
    "greedy_generate(tl_target_model, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a60544a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input prompt: Passport number of Kelly Coleman is\n",
      "Input tokens: tensor([[    0, 12161,   631,  1180,   273, 14943, 32613,   310]],\n",
      "       device='mps:0')\n",
      "Target model generated: ' 030297304<|endoftext|>'\n",
      "Expected PII: ' 030297304'\n",
      "Obtained cache from target model\n",
      "\n",
      "============================================================\n",
      "Baseline Metrics\n",
      "============================================================\n",
      "Target tokens: [470, 1229, 23185, 19321]\n",
      "Decoded tokens: [' 0', '30', '297', '304']\n",
      "\n",
      "Target (memorized) model log prob: -4.0393\n",
      "Control model log prob: -35.2451\n",
      "Difference: +31.2058\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Setup for activation patching: prepare inputs and get baseline metrics\n",
    "test_string = \"Passport number of Kelly Coleman is\"\n",
    "tokens = tl_control_model.to_tokens(test_string)\n",
    "\n",
    "print(f\"Input prompt: {test_string}\")\n",
    "\n",
    "# First, do greedy generation from target model to get the actual expected PII\n",
    "target_generated_text, target_generated_tokens, _ = greedy_generate(tl_target_model, tokens)\n",
    "print(f\"Target model generated: '{target_generated_text}'\")\n",
    "\n",
    "# Extract PII (remove EOS token)\n",
    "expected_pii = target_generated_text.split('<|endoftext|>')[0]\n",
    "print(f\"Expected PII: '{expected_pii}'\")\n",
    "\n",
    "# Get cache from target model (for activation patching)\n",
    "_, target_cache = tl_target_model.run_with_cache(tokens)\n",
    "print(f\"Obtained cache from target model\")\n",
    "\n",
    "# Calculate baseline probabilities\n",
    "target_token_ids, target_token_log_probs, target_seq_log_prob = calculate_target_pii_probability(\n",
    "    tl_target_model, tokens, expected_pii\n",
    ")\n",
    "\n",
    "control_token_ids, control_token_log_probs, control_seq_log_prob = calculate_target_pii_probability(\n",
    "    tl_control_model, tokens, expected_pii\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Baseline Metrics\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Target tokens: {target_token_ids}\")\n",
    "print(f\"Decoded tokens: {[tl_target_model.tokenizer.decode([t]) for t in target_token_ids]}\")\n",
    "print(f\"\\nTarget (memorized) model log prob: {target_seq_log_prob:.4f}\")\n",
    "print(f\"Control model log prob: {control_seq_log_prob:.4f}\")\n",
    "print(f\"Difference: {target_seq_log_prob - control_seq_log_prob:+.4f}\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "68ec9b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total available layers in cache: 111\n",
      "\n",
      "All available layers:\n",
      "  blocks.0.attn.hook_attn_scores\n",
      "  blocks.0.attn.hook_k\n",
      "  blocks.0.attn.hook_pattern\n",
      "  blocks.0.attn.hook_q\n",
      "  blocks.0.attn.hook_rot_k\n",
      "  blocks.0.attn.hook_rot_q\n",
      "  blocks.0.attn.hook_v\n",
      "  blocks.0.attn.hook_z\n",
      "  blocks.0.hook_attn_out\n",
      "  blocks.0.hook_mlp_out\n",
      "  blocks.0.hook_resid_post\n",
      "  blocks.0.hook_resid_pre\n",
      "  blocks.0.ln1.hook_normalized\n",
      "  blocks.0.ln1.hook_scale\n",
      "  blocks.0.ln2.hook_normalized\n",
      "  blocks.0.ln2.hook_scale\n",
      "  blocks.0.mlp.hook_post\n",
      "  blocks.0.mlp.hook_pre\n",
      "  blocks.1.attn.hook_attn_scores\n",
      "  blocks.1.attn.hook_k\n",
      "  blocks.1.attn.hook_pattern\n",
      "  blocks.1.attn.hook_q\n",
      "  blocks.1.attn.hook_rot_k\n",
      "  blocks.1.attn.hook_rot_q\n",
      "  blocks.1.attn.hook_v\n",
      "  blocks.1.attn.hook_z\n",
      "  blocks.1.hook_attn_out\n",
      "  blocks.1.hook_mlp_out\n",
      "  blocks.1.hook_resid_post\n",
      "  blocks.1.hook_resid_pre\n",
      "  blocks.1.ln1.hook_normalized\n",
      "  blocks.1.ln1.hook_scale\n",
      "  blocks.1.ln2.hook_normalized\n",
      "  blocks.1.ln2.hook_scale\n",
      "  blocks.1.mlp.hook_post\n",
      "  blocks.1.mlp.hook_pre\n",
      "  blocks.2.attn.hook_attn_scores\n",
      "  blocks.2.attn.hook_k\n",
      "  blocks.2.attn.hook_pattern\n",
      "  blocks.2.attn.hook_q\n",
      "  blocks.2.attn.hook_rot_k\n",
      "  blocks.2.attn.hook_rot_q\n",
      "  blocks.2.attn.hook_v\n",
      "  blocks.2.attn.hook_z\n",
      "  blocks.2.hook_attn_out\n",
      "  blocks.2.hook_mlp_out\n",
      "  blocks.2.hook_resid_post\n",
      "  blocks.2.hook_resid_pre\n",
      "  blocks.2.ln1.hook_normalized\n",
      "  blocks.2.ln1.hook_scale\n",
      "  blocks.2.ln2.hook_normalized\n",
      "  blocks.2.ln2.hook_scale\n",
      "  blocks.2.mlp.hook_post\n",
      "  blocks.2.mlp.hook_pre\n",
      "  blocks.3.attn.hook_attn_scores\n",
      "  blocks.3.attn.hook_k\n",
      "  blocks.3.attn.hook_pattern\n",
      "  blocks.3.attn.hook_q\n",
      "  blocks.3.attn.hook_rot_k\n",
      "  blocks.3.attn.hook_rot_q\n",
      "  blocks.3.attn.hook_v\n",
      "  blocks.3.attn.hook_z\n",
      "  blocks.3.hook_attn_out\n",
      "  blocks.3.hook_mlp_out\n",
      "  blocks.3.hook_resid_post\n",
      "  blocks.3.hook_resid_pre\n",
      "  blocks.3.ln1.hook_normalized\n",
      "  blocks.3.ln1.hook_scale\n",
      "  blocks.3.ln2.hook_normalized\n",
      "  blocks.3.ln2.hook_scale\n",
      "  blocks.3.mlp.hook_post\n",
      "  blocks.3.mlp.hook_pre\n",
      "  blocks.4.attn.hook_attn_scores\n",
      "  blocks.4.attn.hook_k\n",
      "  blocks.4.attn.hook_pattern\n",
      "  blocks.4.attn.hook_q\n",
      "  blocks.4.attn.hook_rot_k\n",
      "  blocks.4.attn.hook_rot_q\n",
      "  blocks.4.attn.hook_v\n",
      "  blocks.4.attn.hook_z\n",
      "  blocks.4.hook_attn_out\n",
      "  blocks.4.hook_mlp_out\n",
      "  blocks.4.hook_resid_post\n",
      "  blocks.4.hook_resid_pre\n",
      "  blocks.4.ln1.hook_normalized\n",
      "  blocks.4.ln1.hook_scale\n",
      "  blocks.4.ln2.hook_normalized\n",
      "  blocks.4.ln2.hook_scale\n",
      "  blocks.4.mlp.hook_post\n",
      "  blocks.4.mlp.hook_pre\n",
      "  blocks.5.attn.hook_attn_scores\n",
      "  blocks.5.attn.hook_k\n",
      "  blocks.5.attn.hook_pattern\n",
      "  blocks.5.attn.hook_q\n",
      "  blocks.5.attn.hook_rot_k\n",
      "  blocks.5.attn.hook_rot_q\n",
      "  blocks.5.attn.hook_v\n",
      "  blocks.5.attn.hook_z\n",
      "  blocks.5.hook_attn_out\n",
      "  blocks.5.hook_mlp_out\n",
      "  blocks.5.hook_resid_post\n",
      "  blocks.5.hook_resid_pre\n",
      "  blocks.5.ln1.hook_normalized\n",
      "  blocks.5.ln1.hook_scale\n",
      "  blocks.5.ln2.hook_normalized\n",
      "  blocks.5.ln2.hook_scale\n",
      "  blocks.5.mlp.hook_post\n",
      "  blocks.5.mlp.hook_pre\n",
      "  hook_embed\n",
      "  ln_final.hook_normalized\n",
      "  ln_final.hook_scale\n"
     ]
    }
   ],
   "source": [
    "# Print out all available layers from the cache\n",
    "\n",
    "# Get all available layers from the target model cache\n",
    "all_available_layers = sorted(list(target_cache.keys()))\n",
    "\n",
    "print(f\"\\nTotal available layers in cache: {len(all_available_layers)}\\n\")\n",
    "print(\"All available layers:\")\n",
    "for layer_name in all_available_layers:\n",
    "    print(f\"  {layer_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66c981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sequence length: 8\n",
      "============================================================\n",
      "Comprehensive Activation Patching Analysis\n",
      "============================================================\n",
      "Testing 99 different layers available in cache\n",
      "Baseline (no patch) - Control model sequence log prob: -35.2451\n",
      "Target model sequence log prob: -4.0393\n",
      "Expected PII: ' 030297304'\n",
      "\n",
      "\n",
      "0 Patching layer hook_embed\n",
      "Patching layer hook_embed\n",
      "Patching layer hook_embed\n",
      "Patching layer hook_embed\n",
      "Patching layer hook_embed\n",
      "1 Patching layer blocks.0.hook_resid_pre\n",
      "Patching layer blocks.0.hook_resid_pre\n",
      "Patching layer blocks.0.hook_resid_pre\n",
      "Patching layer blocks.0.hook_resid_pre\n",
      "Patching layer blocks.0.hook_resid_pre\n",
      "2 Patching layer blocks.0.ln1.hook_scale\n",
      "Patching layer blocks.0.ln1.hook_scale\n",
      "Patching layer blocks.0.ln1.hook_scale\n",
      "Patching layer blocks.0.ln1.hook_scale\n",
      "Patching layer blocks.0.ln1.hook_scale\n",
      "Patching layer blocks.0.ln1.hook_scale\n",
      "Patching layer blocks.0.ln1.hook_scale\n",
      "Patching layer blocks.0.ln1.hook_scale\n",
      "Patching layer blocks.0.ln1.hook_scale\n",
      "Patching layer blocks.0.ln1.hook_scale\n",
      "Patching layer blocks.0.ln1.hook_scale\n",
      "Patching layer blocks.0.ln1.hook_scale\n",
      "Patching layer blocks.0.ln1.hook_scale\n",
      "3 Patching layer blocks.0.ln1.hook_normalized\n",
      "Patching layer blocks.0.ln1.hook_normalized\n",
      "Patching layer blocks.0.ln1.hook_normalized\n",
      "Patching layer blocks.0.ln1.hook_normalized\n",
      "Patching layer blocks.0.ln1.hook_normalized\n",
      "Patching layer blocks.0.ln1.hook_normalized\n",
      "Patching layer blocks.0.ln1.hook_normalized\n",
      "Patching layer blocks.0.ln1.hook_normalized\n",
      "Patching layer blocks.0.ln1.hook_normalized\n",
      "Patching layer blocks.0.ln1.hook_normalized\n",
      "Patching layer blocks.0.ln1.hook_normalized\n",
      "Patching layer blocks.0.ln1.hook_normalized\n",
      "Patching layer blocks.0.ln1.hook_normalized\n",
      "4 Patching layer blocks.0.attn.hook_q\n",
      "Patching layer blocks.0.attn.hook_q\n",
      "Patching layer blocks.0.attn.hook_q\n",
      "Patching layer blocks.0.attn.hook_q\n",
      "Patching layer blocks.0.attn.hook_q\n",
      "5 Patching layer blocks.0.attn.hook_k\n",
      "Patching layer blocks.0.attn.hook_k\n",
      "Patching layer blocks.0.attn.hook_k\n",
      "Patching layer blocks.0.attn.hook_k\n",
      "Patching layer blocks.0.attn.hook_k\n",
      "6 Patching layer blocks.0.attn.hook_v\n",
      "Patching layer blocks.0.attn.hook_v\n",
      "Patching layer blocks.0.attn.hook_v\n",
      "Patching layer blocks.0.attn.hook_v\n",
      "Patching layer blocks.0.attn.hook_v\n",
      "7 Patching layer blocks.0.attn.hook_rot_q\n",
      "Patching layer blocks.0.attn.hook_rot_q\n",
      "Patching layer blocks.0.attn.hook_rot_q\n",
      "Patching layer blocks.0.attn.hook_rot_q\n",
      "Patching layer blocks.0.attn.hook_rot_q\n",
      "8 Patching layer blocks.0.attn.hook_rot_k\n",
      "Patching layer blocks.0.attn.hook_rot_k\n",
      "Patching layer blocks.0.attn.hook_rot_k\n",
      "Patching layer blocks.0.attn.hook_rot_k\n",
      "Patching layer blocks.0.attn.hook_rot_k\n",
      "9 Patching layer blocks.0.attn.hook_z\n",
      "Patching layer blocks.0.attn.hook_z\n",
      "Patching layer blocks.0.attn.hook_z\n",
      "Patching layer blocks.0.attn.hook_z\n",
      "Patching layer blocks.0.attn.hook_z\n",
      "10 Patching layer blocks.0.hook_attn_out\n",
      "Patching layer blocks.0.hook_attn_out\n",
      "Patching layer blocks.0.hook_attn_out\n",
      "Patching layer blocks.0.hook_attn_out\n",
      "Patching layer blocks.0.hook_attn_out\n",
      "11 Patching layer blocks.0.ln2.hook_scale\n",
      "Patching layer blocks.0.ln2.hook_scale\n",
      "Patching layer blocks.0.ln2.hook_scale\n",
      "Patching layer blocks.0.ln2.hook_scale\n",
      "Patching layer blocks.0.ln2.hook_scale\n",
      "12 Patching layer blocks.0.ln2.hook_normalized\n",
      "Patching layer blocks.0.ln2.hook_normalized\n",
      "Patching layer blocks.0.ln2.hook_normalized\n",
      "Patching layer blocks.0.ln2.hook_normalized\n",
      "Patching layer blocks.0.ln2.hook_normalized\n",
      "13 Patching layer blocks.0.mlp.hook_pre\n",
      "Patching layer blocks.0.mlp.hook_pre\n",
      "Patching layer blocks.0.mlp.hook_pre\n",
      "Patching layer blocks.0.mlp.hook_pre\n",
      "Patching layer blocks.0.mlp.hook_pre\n",
      "14 Patching layer blocks.0.mlp.hook_post\n",
      "Patching layer blocks.0.mlp.hook_post\n",
      "Patching layer blocks.0.mlp.hook_post\n",
      "Patching layer blocks.0.mlp.hook_post\n",
      "Patching layer blocks.0.mlp.hook_post\n",
      "15 Patching layer blocks.0.hook_mlp_out\n",
      "Patching layer blocks.0.hook_mlp_out\n",
      "Patching layer blocks.0.hook_mlp_out\n",
      "Patching layer blocks.0.hook_mlp_out\n",
      "Patching layer blocks.0.hook_mlp_out\n",
      "16 Patching layer blocks.0.hook_resid_post\n",
      "Patching layer blocks.0.hook_resid_post\n",
      "Patching layer blocks.0.hook_resid_post\n",
      "Patching layer blocks.0.hook_resid_post\n",
      "Patching layer blocks.0.hook_resid_post\n",
      "17 Patching layer blocks.1.hook_resid_pre\n",
      "Patching layer blocks.1.hook_resid_pre\n",
      "Patching layer blocks.1.hook_resid_pre\n",
      "Patching layer blocks.1.hook_resid_pre\n",
      "Patching layer blocks.1.hook_resid_pre\n",
      "18 Patching layer blocks.1.ln1.hook_scale\n",
      "Patching layer blocks.1.ln1.hook_scale\n",
      "Patching layer blocks.1.ln1.hook_scale\n",
      "Patching layer blocks.1.ln1.hook_scale\n",
      "Patching layer blocks.1.ln1.hook_scale\n",
      "Patching layer blocks.1.ln1.hook_scale\n",
      "Patching layer blocks.1.ln1.hook_scale\n",
      "Patching layer blocks.1.ln1.hook_scale\n",
      "Patching layer blocks.1.ln1.hook_scale\n",
      "Patching layer blocks.1.ln1.hook_scale\n",
      "Patching layer blocks.1.ln1.hook_scale\n",
      "Patching layer blocks.1.ln1.hook_scale\n",
      "Patching layer blocks.1.ln1.hook_scale\n",
      "19 Patching layer blocks.1.ln1.hook_normalized\n",
      "Patching layer blocks.1.ln1.hook_normalized\n",
      "Patching layer blocks.1.ln1.hook_normalized\n",
      "Patching layer blocks.1.ln1.hook_normalized\n",
      "Patching layer blocks.1.ln1.hook_normalized\n",
      "Patching layer blocks.1.ln1.hook_normalized\n",
      "Patching layer blocks.1.ln1.hook_normalized\n",
      "Patching layer blocks.1.ln1.hook_normalized\n",
      "Patching layer blocks.1.ln1.hook_normalized\n",
      "Patching layer blocks.1.ln1.hook_normalized\n",
      "Patching layer blocks.1.ln1.hook_normalized\n",
      "Patching layer blocks.1.ln1.hook_normalized\n",
      "Patching layer blocks.1.ln1.hook_normalized\n",
      "Processed 20/99 layers...\n",
      "20 Patching layer blocks.1.attn.hook_q\n",
      "Patching layer blocks.1.attn.hook_q\n",
      "Patching layer blocks.1.attn.hook_q\n",
      "Patching layer blocks.1.attn.hook_q\n",
      "Patching layer blocks.1.attn.hook_q\n",
      "21 Patching layer blocks.1.attn.hook_k\n",
      "Patching layer blocks.1.attn.hook_k\n",
      "Patching layer blocks.1.attn.hook_k\n",
      "Patching layer blocks.1.attn.hook_k\n",
      "Patching layer blocks.1.attn.hook_k\n",
      "22 Patching layer blocks.1.attn.hook_v\n",
      "Patching layer blocks.1.attn.hook_v\n",
      "Patching layer blocks.1.attn.hook_v\n",
      "Patching layer blocks.1.attn.hook_v\n",
      "Patching layer blocks.1.attn.hook_v\n",
      "23 Patching layer blocks.1.attn.hook_rot_q\n",
      "Patching layer blocks.1.attn.hook_rot_q\n",
      "Patching layer blocks.1.attn.hook_rot_q\n",
      "Patching layer blocks.1.attn.hook_rot_q\n",
      "Patching layer blocks.1.attn.hook_rot_q\n",
      "24 Patching layer blocks.1.attn.hook_rot_k\n",
      "Patching layer blocks.1.attn.hook_rot_k\n",
      "Patching layer blocks.1.attn.hook_rot_k\n",
      "Patching layer blocks.1.attn.hook_rot_k\n",
      "Patching layer blocks.1.attn.hook_rot_k\n",
      "25 Patching layer blocks.1.attn.hook_z\n",
      "Patching layer blocks.1.attn.hook_z\n",
      "Patching layer blocks.1.attn.hook_z\n",
      "Patching layer blocks.1.attn.hook_z\n",
      "Patching layer blocks.1.attn.hook_z\n",
      "26 Patching layer blocks.1.hook_attn_out\n",
      "Patching layer blocks.1.hook_attn_out\n",
      "Patching layer blocks.1.hook_attn_out\n",
      "Patching layer blocks.1.hook_attn_out\n",
      "Patching layer blocks.1.hook_attn_out\n",
      "27 Patching layer blocks.1.ln2.hook_scale\n",
      "Patching layer blocks.1.ln2.hook_scale\n",
      "Patching layer blocks.1.ln2.hook_scale\n",
      "Patching layer blocks.1.ln2.hook_scale\n",
      "Patching layer blocks.1.ln2.hook_scale\n",
      "28 Patching layer blocks.1.ln2.hook_normalized\n",
      "Patching layer blocks.1.ln2.hook_normalized\n",
      "Patching layer blocks.1.ln2.hook_normalized\n",
      "Patching layer blocks.1.ln2.hook_normalized\n",
      "Patching layer blocks.1.ln2.hook_normalized\n",
      "29 Patching layer blocks.1.mlp.hook_pre\n",
      "Patching layer blocks.1.mlp.hook_pre\n",
      "Patching layer blocks.1.mlp.hook_pre\n",
      "Patching layer blocks.1.mlp.hook_pre\n",
      "Patching layer blocks.1.mlp.hook_pre\n",
      "30 Patching layer blocks.1.mlp.hook_post\n",
      "Patching layer blocks.1.mlp.hook_post\n",
      "Patching layer blocks.1.mlp.hook_post\n",
      "Patching layer blocks.1.mlp.hook_post\n",
      "Patching layer blocks.1.mlp.hook_post\n",
      "31 Patching layer blocks.1.hook_mlp_out\n",
      "Patching layer blocks.1.hook_mlp_out\n",
      "Patching layer blocks.1.hook_mlp_out\n",
      "Patching layer blocks.1.hook_mlp_out\n",
      "Patching layer blocks.1.hook_mlp_out\n",
      "32 Patching layer blocks.1.hook_resid_post\n",
      "Patching layer blocks.1.hook_resid_post\n",
      "Patching layer blocks.1.hook_resid_post\n",
      "Patching layer blocks.1.hook_resid_post\n",
      "Patching layer blocks.1.hook_resid_post\n",
      "33 Patching layer blocks.2.hook_resid_pre\n",
      "Patching layer blocks.2.hook_resid_pre\n",
      "Patching layer blocks.2.hook_resid_pre\n",
      "Patching layer blocks.2.hook_resid_pre\n",
      "Patching layer blocks.2.hook_resid_pre\n",
      "34 Patching layer blocks.2.ln1.hook_scale\n",
      "Patching layer blocks.2.ln1.hook_scale\n",
      "Patching layer blocks.2.ln1.hook_scale\n",
      "Patching layer blocks.2.ln1.hook_scale\n",
      "Patching layer blocks.2.ln1.hook_scale\n",
      "Patching layer blocks.2.ln1.hook_scale\n",
      "Patching layer blocks.2.ln1.hook_scale\n",
      "Patching layer blocks.2.ln1.hook_scale\n",
      "Patching layer blocks.2.ln1.hook_scale\n",
      "Patching layer blocks.2.ln1.hook_scale\n",
      "Patching layer blocks.2.ln1.hook_scale\n",
      "Patching layer blocks.2.ln1.hook_scale\n",
      "Patching layer blocks.2.ln1.hook_scale\n",
      "35 Patching layer blocks.2.ln1.hook_normalized\n",
      "Patching layer blocks.2.ln1.hook_normalized\n",
      "Patching layer blocks.2.ln1.hook_normalized\n",
      "Patching layer blocks.2.ln1.hook_normalized\n",
      "Patching layer blocks.2.ln1.hook_normalized\n",
      "Patching layer blocks.2.ln1.hook_normalized\n",
      "Patching layer blocks.2.ln1.hook_normalized\n",
      "Patching layer blocks.2.ln1.hook_normalized\n",
      "Patching layer blocks.2.ln1.hook_normalized\n",
      "Patching layer blocks.2.ln1.hook_normalized\n",
      "Patching layer blocks.2.ln1.hook_normalized\n",
      "Patching layer blocks.2.ln1.hook_normalized\n",
      "Patching layer blocks.2.ln1.hook_normalized\n",
      "36 Patching layer blocks.2.attn.hook_q\n",
      "Patching layer blocks.2.attn.hook_q\n",
      "Patching layer blocks.2.attn.hook_q\n",
      "Patching layer blocks.2.attn.hook_q\n",
      "Patching layer blocks.2.attn.hook_q\n",
      "37 Patching layer blocks.2.attn.hook_k\n",
      "Patching layer blocks.2.attn.hook_k\n",
      "Patching layer blocks.2.attn.hook_k\n",
      "Patching layer blocks.2.attn.hook_k\n",
      "Patching layer blocks.2.attn.hook_k\n",
      "38 Patching layer blocks.2.attn.hook_v\n",
      "Patching layer blocks.2.attn.hook_v\n",
      "Patching layer blocks.2.attn.hook_v\n",
      "Patching layer blocks.2.attn.hook_v\n",
      "Patching layer blocks.2.attn.hook_v\n",
      "39 Patching layer blocks.2.attn.hook_rot_q\n",
      "Patching layer blocks.2.attn.hook_rot_q\n",
      "Patching layer blocks.2.attn.hook_rot_q\n",
      "Patching layer blocks.2.attn.hook_rot_q\n",
      "Patching layer blocks.2.attn.hook_rot_q\n",
      "Processed 40/99 layers...\n",
      "40 Patching layer blocks.2.attn.hook_rot_k\n",
      "Patching layer blocks.2.attn.hook_rot_k\n",
      "Patching layer blocks.2.attn.hook_rot_k\n",
      "Patching layer blocks.2.attn.hook_rot_k\n",
      "Patching layer blocks.2.attn.hook_rot_k\n",
      "41 Patching layer blocks.2.attn.hook_z\n",
      "Patching layer blocks.2.attn.hook_z\n",
      "Patching layer blocks.2.attn.hook_z\n",
      "Patching layer blocks.2.attn.hook_z\n",
      "Patching layer blocks.2.attn.hook_z\n",
      "42 Patching layer blocks.2.hook_attn_out\n",
      "Patching layer blocks.2.hook_attn_out\n",
      "Patching layer blocks.2.hook_attn_out\n",
      "Patching layer blocks.2.hook_attn_out\n",
      "Patching layer blocks.2.hook_attn_out\n",
      "43 Patching layer blocks.2.ln2.hook_scale\n",
      "Patching layer blocks.2.ln2.hook_scale\n",
      "Patching layer blocks.2.ln2.hook_scale\n",
      "Patching layer blocks.2.ln2.hook_scale\n",
      "Patching layer blocks.2.ln2.hook_scale\n",
      "44 Patching layer blocks.2.ln2.hook_normalized\n",
      "Patching layer blocks.2.ln2.hook_normalized\n",
      "Patching layer blocks.2.ln2.hook_normalized\n",
      "Patching layer blocks.2.ln2.hook_normalized\n",
      "Patching layer blocks.2.ln2.hook_normalized\n",
      "45 Patching layer blocks.2.mlp.hook_pre\n",
      "Patching layer blocks.2.mlp.hook_pre\n",
      "Patching layer blocks.2.mlp.hook_pre\n",
      "Patching layer blocks.2.mlp.hook_pre\n",
      "Patching layer blocks.2.mlp.hook_pre\n",
      "46 Patching layer blocks.2.mlp.hook_post\n",
      "Patching layer blocks.2.mlp.hook_post\n",
      "Patching layer blocks.2.mlp.hook_post\n",
      "Patching layer blocks.2.mlp.hook_post\n",
      "Patching layer blocks.2.mlp.hook_post\n",
      "47 Patching layer blocks.2.hook_mlp_out\n",
      "Patching layer blocks.2.hook_mlp_out\n",
      "Patching layer blocks.2.hook_mlp_out\n",
      "Patching layer blocks.2.hook_mlp_out\n",
      "Patching layer blocks.2.hook_mlp_out\n",
      "48 Patching layer blocks.2.hook_resid_post\n",
      "Patching layer blocks.2.hook_resid_post\n",
      "Patching layer blocks.2.hook_resid_post\n",
      "Patching layer blocks.2.hook_resid_post\n",
      "Patching layer blocks.2.hook_resid_post\n",
      "49 Patching layer blocks.3.hook_resid_pre\n",
      "Patching layer blocks.3.hook_resid_pre\n",
      "Patching layer blocks.3.hook_resid_pre\n",
      "Patching layer blocks.3.hook_resid_pre\n",
      "Patching layer blocks.3.hook_resid_pre\n",
      "50 Patching layer blocks.3.ln1.hook_scale\n",
      "Patching layer blocks.3.ln1.hook_scale\n",
      "Patching layer blocks.3.ln1.hook_scale\n",
      "Patching layer blocks.3.ln1.hook_scale\n",
      "Patching layer blocks.3.ln1.hook_scale\n",
      "Patching layer blocks.3.ln1.hook_scale\n",
      "Patching layer blocks.3.ln1.hook_scale\n",
      "Patching layer blocks.3.ln1.hook_scale\n",
      "Patching layer blocks.3.ln1.hook_scale\n",
      "Patching layer blocks.3.ln1.hook_scale\n",
      "Patching layer blocks.3.ln1.hook_scale\n",
      "Patching layer blocks.3.ln1.hook_scale\n",
      "Patching layer blocks.3.ln1.hook_scale\n",
      "51 Patching layer blocks.3.ln1.hook_normalized\n",
      "Patching layer blocks.3.ln1.hook_normalized\n",
      "Patching layer blocks.3.ln1.hook_normalized\n",
      "Patching layer blocks.3.ln1.hook_normalized\n",
      "Patching layer blocks.3.ln1.hook_normalized\n",
      "Patching layer blocks.3.ln1.hook_normalized\n",
      "Patching layer blocks.3.ln1.hook_normalized\n",
      "Patching layer blocks.3.ln1.hook_normalized\n",
      "Patching layer blocks.3.ln1.hook_normalized\n",
      "Patching layer blocks.3.ln1.hook_normalized\n",
      "Patching layer blocks.3.ln1.hook_normalized\n",
      "Patching layer blocks.3.ln1.hook_normalized\n",
      "Patching layer blocks.3.ln1.hook_normalized\n",
      "52 Patching layer blocks.3.attn.hook_q\n",
      "Patching layer blocks.3.attn.hook_q\n",
      "Patching layer blocks.3.attn.hook_q\n",
      "Patching layer blocks.3.attn.hook_q\n",
      "Patching layer blocks.3.attn.hook_q\n",
      "53 Patching layer blocks.3.attn.hook_k\n",
      "Patching layer blocks.3.attn.hook_k\n",
      "Patching layer blocks.3.attn.hook_k\n",
      "Patching layer blocks.3.attn.hook_k\n",
      "Patching layer blocks.3.attn.hook_k\n",
      "54 Patching layer blocks.3.attn.hook_v\n",
      "Patching layer blocks.3.attn.hook_v\n",
      "Patching layer blocks.3.attn.hook_v\n",
      "Patching layer blocks.3.attn.hook_v\n",
      "Patching layer blocks.3.attn.hook_v\n",
      "55 Patching layer blocks.3.attn.hook_rot_q\n",
      "Patching layer blocks.3.attn.hook_rot_q\n",
      "Patching layer blocks.3.attn.hook_rot_q\n",
      "Patching layer blocks.3.attn.hook_rot_q\n",
      "Patching layer blocks.3.attn.hook_rot_q\n",
      "56 Patching layer blocks.3.attn.hook_rot_k\n",
      "Patching layer blocks.3.attn.hook_rot_k\n",
      "Patching layer blocks.3.attn.hook_rot_k\n",
      "Patching layer blocks.3.attn.hook_rot_k\n",
      "Patching layer blocks.3.attn.hook_rot_k\n",
      "57 Patching layer blocks.3.attn.hook_z\n",
      "Patching layer blocks.3.attn.hook_z\n",
      "Patching layer blocks.3.attn.hook_z\n",
      "Patching layer blocks.3.attn.hook_z\n",
      "Patching layer blocks.3.attn.hook_z\n",
      "58 Patching layer blocks.3.hook_attn_out\n",
      "Patching layer blocks.3.hook_attn_out\n",
      "Patching layer blocks.3.hook_attn_out\n",
      "Patching layer blocks.3.hook_attn_out\n",
      "Patching layer blocks.3.hook_attn_out\n",
      "59 Patching layer blocks.3.ln2.hook_scale\n",
      "Patching layer blocks.3.ln2.hook_scale\n",
      "Patching layer blocks.3.ln2.hook_scale\n",
      "Patching layer blocks.3.ln2.hook_scale\n",
      "Patching layer blocks.3.ln2.hook_scale\n",
      "Processed 60/99 layers...\n",
      "60 Patching layer blocks.3.ln2.hook_normalized\n",
      "Patching layer blocks.3.ln2.hook_normalized\n",
      "Patching layer blocks.3.ln2.hook_normalized\n",
      "Patching layer blocks.3.ln2.hook_normalized\n",
      "Patching layer blocks.3.ln2.hook_normalized\n",
      "61 Patching layer blocks.3.mlp.hook_pre\n",
      "Patching layer blocks.3.mlp.hook_pre\n",
      "Patching layer blocks.3.mlp.hook_pre\n",
      "Patching layer blocks.3.mlp.hook_pre\n",
      "Patching layer blocks.3.mlp.hook_pre\n",
      "62 Patching layer blocks.3.mlp.hook_post\n",
      "Patching layer blocks.3.mlp.hook_post\n",
      "Patching layer blocks.3.mlp.hook_post\n",
      "Patching layer blocks.3.mlp.hook_post\n",
      "Patching layer blocks.3.mlp.hook_post\n",
      "63 Patching layer blocks.3.hook_mlp_out\n",
      "Patching layer blocks.3.hook_mlp_out\n",
      "Patching layer blocks.3.hook_mlp_out\n",
      "Patching layer blocks.3.hook_mlp_out\n",
      "Patching layer blocks.3.hook_mlp_out\n",
      "64 Patching layer blocks.3.hook_resid_post\n",
      "Patching layer blocks.3.hook_resid_post\n",
      "Patching layer blocks.3.hook_resid_post\n",
      "Patching layer blocks.3.hook_resid_post\n",
      "Patching layer blocks.3.hook_resid_post\n",
      "65 Patching layer blocks.4.hook_resid_pre\n",
      "Patching layer blocks.4.hook_resid_pre\n",
      "Patching layer blocks.4.hook_resid_pre\n",
      "Patching layer blocks.4.hook_resid_pre\n",
      "Patching layer blocks.4.hook_resid_pre\n",
      "66 Patching layer blocks.4.ln1.hook_scale\n",
      "Patching layer blocks.4.ln1.hook_scale\n",
      "Patching layer blocks.4.ln1.hook_scale\n",
      "Patching layer blocks.4.ln1.hook_scale\n",
      "Patching layer blocks.4.ln1.hook_scale\n",
      "Patching layer blocks.4.ln1.hook_scale\n",
      "Patching layer blocks.4.ln1.hook_scale\n",
      "Patching layer blocks.4.ln1.hook_scale\n",
      "Patching layer blocks.4.ln1.hook_scale\n",
      "Patching layer blocks.4.ln1.hook_scale\n",
      "Patching layer blocks.4.ln1.hook_scale\n",
      "Patching layer blocks.4.ln1.hook_scale\n",
      "Patching layer blocks.4.ln1.hook_scale\n",
      "67 Patching layer blocks.4.ln1.hook_normalized\n",
      "Patching layer blocks.4.ln1.hook_normalized\n",
      "Patching layer blocks.4.ln1.hook_normalized\n",
      "Patching layer blocks.4.ln1.hook_normalized\n",
      "Patching layer blocks.4.ln1.hook_normalized\n",
      "Patching layer blocks.4.ln1.hook_normalized\n",
      "Patching layer blocks.4.ln1.hook_normalized\n",
      "Patching layer blocks.4.ln1.hook_normalized\n",
      "Patching layer blocks.4.ln1.hook_normalized\n",
      "Patching layer blocks.4.ln1.hook_normalized\n",
      "Patching layer blocks.4.ln1.hook_normalized\n",
      "Patching layer blocks.4.ln1.hook_normalized\n",
      "Patching layer blocks.4.ln1.hook_normalized\n",
      "68 Patching layer blocks.4.attn.hook_q\n",
      "Patching layer blocks.4.attn.hook_q\n",
      "Patching layer blocks.4.attn.hook_q\n",
      "Patching layer blocks.4.attn.hook_q\n",
      "Patching layer blocks.4.attn.hook_q\n",
      "69 Patching layer blocks.4.attn.hook_k\n",
      "Patching layer blocks.4.attn.hook_k\n",
      "Patching layer blocks.4.attn.hook_k\n",
      "Patching layer blocks.4.attn.hook_k\n",
      "Patching layer blocks.4.attn.hook_k\n",
      "70 Patching layer blocks.4.attn.hook_v\n",
      "Patching layer blocks.4.attn.hook_v\n",
      "Patching layer blocks.4.attn.hook_v\n",
      "Patching layer blocks.4.attn.hook_v\n",
      "Patching layer blocks.4.attn.hook_v\n",
      "71 Patching layer blocks.4.attn.hook_rot_q\n",
      "Patching layer blocks.4.attn.hook_rot_q\n",
      "Patching layer blocks.4.attn.hook_rot_q\n",
      "Patching layer blocks.4.attn.hook_rot_q\n",
      "Patching layer blocks.4.attn.hook_rot_q\n",
      "72 Patching layer blocks.4.attn.hook_rot_k\n",
      "Patching layer blocks.4.attn.hook_rot_k\n",
      "Patching layer blocks.4.attn.hook_rot_k\n",
      "Patching layer blocks.4.attn.hook_rot_k\n",
      "Patching layer blocks.4.attn.hook_rot_k\n",
      "73 Patching layer blocks.4.attn.hook_z\n",
      "Patching layer blocks.4.attn.hook_z\n",
      "Patching layer blocks.4.attn.hook_z\n",
      "Patching layer blocks.4.attn.hook_z\n",
      "Patching layer blocks.4.attn.hook_z\n",
      "74 Patching layer blocks.4.hook_attn_out\n",
      "Patching layer blocks.4.hook_attn_out\n",
      "Patching layer blocks.4.hook_attn_out\n",
      "Patching layer blocks.4.hook_attn_out\n",
      "Patching layer blocks.4.hook_attn_out\n",
      "75 Patching layer blocks.4.ln2.hook_scale\n",
      "Patching layer blocks.4.ln2.hook_scale\n",
      "Patching layer blocks.4.ln2.hook_scale\n",
      "Patching layer blocks.4.ln2.hook_scale\n",
      "Patching layer blocks.4.ln2.hook_scale\n",
      "76 Patching layer blocks.4.ln2.hook_normalized\n",
      "Patching layer blocks.4.ln2.hook_normalized\n",
      "Patching layer blocks.4.ln2.hook_normalized\n",
      "Patching layer blocks.4.ln2.hook_normalized\n",
      "Patching layer blocks.4.ln2.hook_normalized\n",
      "77 Patching layer blocks.4.mlp.hook_pre\n",
      "Patching layer blocks.4.mlp.hook_pre\n",
      "Patching layer blocks.4.mlp.hook_pre\n",
      "Patching layer blocks.4.mlp.hook_pre\n",
      "Patching layer blocks.4.mlp.hook_pre\n",
      "78 Patching layer blocks.4.mlp.hook_post\n",
      "Patching layer blocks.4.mlp.hook_post\n",
      "Patching layer blocks.4.mlp.hook_post\n",
      "Patching layer blocks.4.mlp.hook_post\n",
      "Patching layer blocks.4.mlp.hook_post\n",
      "79 Patching layer blocks.4.hook_mlp_out\n",
      "Patching layer blocks.4.hook_mlp_out\n",
      "Patching layer blocks.4.hook_mlp_out\n",
      "Patching layer blocks.4.hook_mlp_out\n",
      "Patching layer blocks.4.hook_mlp_out\n",
      "Processed 80/99 layers...\n",
      "80 Patching layer blocks.4.hook_resid_post\n",
      "Patching layer blocks.4.hook_resid_post\n",
      "Patching layer blocks.4.hook_resid_post\n",
      "Patching layer blocks.4.hook_resid_post\n",
      "Patching layer blocks.4.hook_resid_post\n",
      "81 Patching layer blocks.5.hook_resid_pre\n",
      "Patching layer blocks.5.hook_resid_pre\n",
      "Patching layer blocks.5.hook_resid_pre\n",
      "Patching layer blocks.5.hook_resid_pre\n",
      "Patching layer blocks.5.hook_resid_pre\n",
      "82 Patching layer blocks.5.ln1.hook_scale\n",
      "Patching layer blocks.5.ln1.hook_scale\n",
      "Patching layer blocks.5.ln1.hook_scale\n",
      "Patching layer blocks.5.ln1.hook_scale\n",
      "Patching layer blocks.5.ln1.hook_scale\n",
      "Patching layer blocks.5.ln1.hook_scale\n",
      "Patching layer blocks.5.ln1.hook_scale\n",
      "Patching layer blocks.5.ln1.hook_scale\n",
      "Patching layer blocks.5.ln1.hook_scale\n",
      "Patching layer blocks.5.ln1.hook_scale\n",
      "Patching layer blocks.5.ln1.hook_scale\n",
      "Patching layer blocks.5.ln1.hook_scale\n",
      "Patching layer blocks.5.ln1.hook_scale\n",
      "83 Patching layer blocks.5.ln1.hook_normalized\n",
      "Patching layer blocks.5.ln1.hook_normalized\n",
      "Patching layer blocks.5.ln1.hook_normalized\n",
      "Patching layer blocks.5.ln1.hook_normalized\n",
      "Patching layer blocks.5.ln1.hook_normalized\n",
      "Patching layer blocks.5.ln1.hook_normalized\n",
      "Patching layer blocks.5.ln1.hook_normalized\n",
      "Patching layer blocks.5.ln1.hook_normalized\n",
      "Patching layer blocks.5.ln1.hook_normalized\n",
      "Patching layer blocks.5.ln1.hook_normalized\n",
      "Patching layer blocks.5.ln1.hook_normalized\n",
      "Patching layer blocks.5.ln1.hook_normalized\n",
      "Patching layer blocks.5.ln1.hook_normalized\n",
      "84 Patching layer blocks.5.attn.hook_q\n",
      "Patching layer blocks.5.attn.hook_q\n",
      "Patching layer blocks.5.attn.hook_q\n",
      "Patching layer blocks.5.attn.hook_q\n",
      "Patching layer blocks.5.attn.hook_q\n",
      "85 Patching layer blocks.5.attn.hook_k\n",
      "Patching layer blocks.5.attn.hook_k\n",
      "Patching layer blocks.5.attn.hook_k\n",
      "Patching layer blocks.5.attn.hook_k\n",
      "Patching layer blocks.5.attn.hook_k\n",
      "86 Patching layer blocks.5.attn.hook_v\n",
      "Patching layer blocks.5.attn.hook_v\n",
      "Patching layer blocks.5.attn.hook_v\n",
      "Patching layer blocks.5.attn.hook_v\n",
      "Patching layer blocks.5.attn.hook_v\n",
      "87 Patching layer blocks.5.attn.hook_rot_q\n",
      "Patching layer blocks.5.attn.hook_rot_q\n",
      "Patching layer blocks.5.attn.hook_rot_q\n",
      "Patching layer blocks.5.attn.hook_rot_q\n",
      "Patching layer blocks.5.attn.hook_rot_q\n",
      "88 Patching layer blocks.5.attn.hook_rot_k\n",
      "Patching layer blocks.5.attn.hook_rot_k\n",
      "Patching layer blocks.5.attn.hook_rot_k\n",
      "Patching layer blocks.5.attn.hook_rot_k\n",
      "Patching layer blocks.5.attn.hook_rot_k\n",
      "89 Patching layer blocks.5.attn.hook_z\n",
      "Patching layer blocks.5.attn.hook_z\n",
      "Patching layer blocks.5.attn.hook_z\n",
      "Patching layer blocks.5.attn.hook_z\n",
      "Patching layer blocks.5.attn.hook_z\n",
      "90 Patching layer blocks.5.hook_attn_out\n",
      "Patching layer blocks.5.hook_attn_out\n",
      "Patching layer blocks.5.hook_attn_out\n",
      "Patching layer blocks.5.hook_attn_out\n",
      "Patching layer blocks.5.hook_attn_out\n",
      "91 Patching layer blocks.5.ln2.hook_scale\n",
      "Patching layer blocks.5.ln2.hook_scale\n",
      "Patching layer blocks.5.ln2.hook_scale\n",
      "Patching layer blocks.5.ln2.hook_scale\n",
      "Patching layer blocks.5.ln2.hook_scale\n",
      "92 Patching layer blocks.5.ln2.hook_normalized\n",
      "Patching layer blocks.5.ln2.hook_normalized\n",
      "Patching layer blocks.5.ln2.hook_normalized\n",
      "Patching layer blocks.5.ln2.hook_normalized\n",
      "Patching layer blocks.5.ln2.hook_normalized\n",
      "93 Patching layer blocks.5.mlp.hook_pre\n",
      "Patching layer blocks.5.mlp.hook_pre\n",
      "Patching layer blocks.5.mlp.hook_pre\n",
      "Patching layer blocks.5.mlp.hook_pre\n",
      "Patching layer blocks.5.mlp.hook_pre\n",
      "94 Patching layer blocks.5.mlp.hook_post\n",
      "Patching layer blocks.5.mlp.hook_post\n",
      "Patching layer blocks.5.mlp.hook_post\n",
      "Patching layer blocks.5.mlp.hook_post\n",
      "Patching layer blocks.5.mlp.hook_post\n",
      "95 Patching layer blocks.5.hook_mlp_out\n",
      "Patching layer blocks.5.hook_mlp_out\n",
      "Patching layer blocks.5.hook_mlp_out\n",
      "Patching layer blocks.5.hook_mlp_out\n",
      "Patching layer blocks.5.hook_mlp_out\n",
      "96 Patching layer blocks.5.hook_resid_post\n",
      "Patching layer blocks.5.hook_resid_post\n",
      "Patching layer blocks.5.hook_resid_post\n",
      "Patching layer blocks.5.hook_resid_post\n",
      "Patching layer blocks.5.hook_resid_post\n",
      "97 Patching layer ln_final.hook_scale\n",
      "Patching layer ln_final.hook_scale\n",
      "Patching layer ln_final.hook_scale\n",
      "Patching layer ln_final.hook_scale\n",
      "Patching layer ln_final.hook_scale\n",
      "98 Patching layer ln_final.hook_normalized\n",
      "Patching layer ln_final.hook_normalized\n",
      "Patching layer ln_final.hook_normalized\n",
      "Patching layer ln_final.hook_normalized\n",
      "Patching layer ln_final.hook_normalized\n",
      "Completed testing all 99 layers!\n",
      "\n",
      "============================================================\n",
      "Top 20 Layers by Log Prob Improvement\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Number</th>\n",
       "      <th>Log Prob Improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>blocks.5.hook_resid_pre</td>\n",
       "      <td>Residual Pre</td>\n",
       "      <td>5</td>\n",
       "      <td>4.832985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>blocks.4.hook_resid_post</td>\n",
       "      <td>Residual Post</td>\n",
       "      <td>4</td>\n",
       "      <td>4.832985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>blocks.4.hook_resid_pre</td>\n",
       "      <td>Residual Pre</td>\n",
       "      <td>4</td>\n",
       "      <td>3.886961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>blocks.3.hook_resid_post</td>\n",
       "      <td>Residual Post</td>\n",
       "      <td>3</td>\n",
       "      <td>3.886961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>blocks.2.attn.hook_k</td>\n",
       "      <td>Key</td>\n",
       "      <td>2</td>\n",
       "      <td>2.974463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>blocks.2.attn.hook_rot_k</td>\n",
       "      <td>Rotary K</td>\n",
       "      <td>2</td>\n",
       "      <td>2.974463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hook_embed</td>\n",
       "      <td>Embedding</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.858965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blocks.0.hook_resid_pre</td>\n",
       "      <td>Residual Pre</td>\n",
       "      <td>0</td>\n",
       "      <td>2.858965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>blocks.3.hook_mlp_out</td>\n",
       "      <td>MLP Output</td>\n",
       "      <td>3</td>\n",
       "      <td>2.810335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>blocks.4.hook_mlp_out</td>\n",
       "      <td>MLP Output</td>\n",
       "      <td>4</td>\n",
       "      <td>2.770432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>blocks.3.mlp.hook_pre</td>\n",
       "      <td>MLP Pre-activation</td>\n",
       "      <td>3</td>\n",
       "      <td>2.659291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>blocks.3.mlp.hook_post</td>\n",
       "      <td>MLP Post-activation</td>\n",
       "      <td>3</td>\n",
       "      <td>2.659291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blocks.5.hook_mlp_out</td>\n",
       "      <td>MLP Output</td>\n",
       "      <td>5</td>\n",
       "      <td>2.519445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blocks.5.hook_resid_post</td>\n",
       "      <td>Residual Post</td>\n",
       "      <td>5</td>\n",
       "      <td>2.334048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ln_final.hook_normalized</td>\n",
       "      <td>Final LayerNorm</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.334048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blocks.0.ln1.hook_normalized</td>\n",
       "      <td>LN1 Normalized</td>\n",
       "      <td>0</td>\n",
       "      <td>2.296327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>blocks.5.ln2.hook_normalized</td>\n",
       "      <td>LN2 Normalized</td>\n",
       "      <td>5</td>\n",
       "      <td>2.199995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>blocks.2.hook_resid_pre</td>\n",
       "      <td>Residual Pre</td>\n",
       "      <td>2</td>\n",
       "      <td>2.104969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>blocks.1.hook_resid_post</td>\n",
       "      <td>Residual Post</td>\n",
       "      <td>1</td>\n",
       "      <td>2.104969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>blocks.5.mlp.hook_pre</td>\n",
       "      <td>MLP Pre-activation</td>\n",
       "      <td>5</td>\n",
       "      <td>2.021995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Layer           Layer Type  Layer Number  \\\n",
       "81       blocks.5.hook_resid_pre         Residual Pre             5   \n",
       "80      blocks.4.hook_resid_post        Residual Post             4   \n",
       "65       blocks.4.hook_resid_pre         Residual Pre             4   \n",
       "64      blocks.3.hook_resid_post        Residual Post             3   \n",
       "37          blocks.2.attn.hook_k                  Key             2   \n",
       "40      blocks.2.attn.hook_rot_k             Rotary K             2   \n",
       "0                     hook_embed            Embedding            -1   \n",
       "1        blocks.0.hook_resid_pre         Residual Pre             0   \n",
       "63         blocks.3.hook_mlp_out           MLP Output             3   \n",
       "79         blocks.4.hook_mlp_out           MLP Output             4   \n",
       "61         blocks.3.mlp.hook_pre   MLP Pre-activation             3   \n",
       "62        blocks.3.mlp.hook_post  MLP Post-activation             3   \n",
       "95         blocks.5.hook_mlp_out           MLP Output             5   \n",
       "96      blocks.5.hook_resid_post        Residual Post             5   \n",
       "98      ln_final.hook_normalized      Final LayerNorm            -1   \n",
       "3   blocks.0.ln1.hook_normalized       LN1 Normalized             0   \n",
       "92  blocks.5.ln2.hook_normalized       LN2 Normalized             5   \n",
       "33       blocks.2.hook_resid_pre         Residual Pre             2   \n",
       "32      blocks.1.hook_resid_post        Residual Post             1   \n",
       "93         blocks.5.mlp.hook_pre   MLP Pre-activation             5   \n",
       "\n",
       "    Log Prob Improvement  \n",
       "81              4.832985  \n",
       "80              4.832985  \n",
       "65              3.886961  \n",
       "64              3.886961  \n",
       "37              2.974463  \n",
       "40              2.974463  \n",
       "0               2.858965  \n",
       "1               2.858965  \n",
       "63              2.810335  \n",
       "79              2.770432  \n",
       "61              2.659291  \n",
       "62              2.659291  \n",
       "95              2.519445  \n",
       "96              2.334048  \n",
       "98              2.334048  \n",
       "3               2.296327  \n",
       "92              2.199995  \n",
       "33              2.104969  \n",
       "32              2.104969  \n",
       "93              2.021995  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Bottom 10 Layers (Most Harmful)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Number</th>\n",
       "      <th>Log Prob Improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>blocks.3.attn.hook_k</td>\n",
       "      <td>Key</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.209264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>blocks.5.attn.hook_rot_k</td>\n",
       "      <td>Rotary K</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.209812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>blocks.5.attn.hook_k</td>\n",
       "      <td>Key</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.209812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>blocks.0.mlp.hook_post</td>\n",
       "      <td>MLP Post-activation</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.281024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>blocks.0.mlp.hook_pre</td>\n",
       "      <td>MLP Pre-activation</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.281024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>blocks.1.ln2.hook_normalized</td>\n",
       "      <td>LN2 Normalized</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.311628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>blocks.2.hook_mlp_out</td>\n",
       "      <td>MLP Output</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.404104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>blocks.2.mlp.hook_pre</td>\n",
       "      <td>MLP Pre-activation</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.081350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>blocks.2.mlp.hook_post</td>\n",
       "      <td>MLP Post-activation</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.081350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ln_final.hook_scale</td>\n",
       "      <td>Final LayerNorm</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.659567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Layer           Layer Type  Layer Number  \\\n",
       "53          blocks.3.attn.hook_k                  Key             3   \n",
       "88      blocks.5.attn.hook_rot_k             Rotary K             5   \n",
       "85          blocks.5.attn.hook_k                  Key             5   \n",
       "14        blocks.0.mlp.hook_post  MLP Post-activation             0   \n",
       "13         blocks.0.mlp.hook_pre   MLP Pre-activation             0   \n",
       "28  blocks.1.ln2.hook_normalized       LN2 Normalized             1   \n",
       "47         blocks.2.hook_mlp_out           MLP Output             2   \n",
       "45         blocks.2.mlp.hook_pre   MLP Pre-activation             2   \n",
       "46        blocks.2.mlp.hook_post  MLP Post-activation             2   \n",
       "97           ln_final.hook_scale      Final LayerNorm            -1   \n",
       "\n",
       "    Log Prob Improvement  \n",
       "53             -0.209264  \n",
       "88             -0.209812  \n",
       "85             -0.209812  \n",
       "14             -0.281024  \n",
       "13             -0.281024  \n",
       "28             -0.311628  \n",
       "47             -0.404104  \n",
       "45             -1.081350  \n",
       "46             -1.081350  \n",
       "97             -1.659567  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Summary by Layer Type (sorted by mean improvement)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Improvement</th>\n",
       "      <th>Max Improvement</th>\n",
       "      <th>Min Improvement</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Residual Pre</th>\n",
       "      <td>2.8819</td>\n",
       "      <td>4.8330</td>\n",
       "      <td>1.6056</td>\n",
       "      <td>1.2509</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embedding</th>\n",
       "      <td>2.8590</td>\n",
       "      <td>2.8590</td>\n",
       "      <td>2.8590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual Post</th>\n",
       "      <td>2.7945</td>\n",
       "      <td>4.8330</td>\n",
       "      <td>1.6056</td>\n",
       "      <td>1.2710</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Output</th>\n",
       "      <td>1.5241</td>\n",
       "      <td>2.8103</td>\n",
       "      <td>-0.4041</td>\n",
       "      <td>1.3913</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attention Output</th>\n",
       "      <td>1.0075</td>\n",
       "      <td>1.7497</td>\n",
       "      <td>-0.1208</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attention Z</th>\n",
       "      <td>0.9517</td>\n",
       "      <td>1.9289</td>\n",
       "      <td>-0.1669</td>\n",
       "      <td>0.8623</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LN2 Normalized</th>\n",
       "      <td>0.9408</td>\n",
       "      <td>2.2000</td>\n",
       "      <td>-0.3116</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Pre-activation</th>\n",
       "      <td>0.8776</td>\n",
       "      <td>2.6593</td>\n",
       "      <td>-1.0814</td>\n",
       "      <td>1.4632</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Post-activation</th>\n",
       "      <td>0.8776</td>\n",
       "      <td>2.6593</td>\n",
       "      <td>-1.0814</td>\n",
       "      <td>1.4632</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LN1 Normalized</th>\n",
       "      <td>0.8554</td>\n",
       "      <td>2.2963</td>\n",
       "      <td>0.1554</td>\n",
       "      <td>0.7943</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rotary K</th>\n",
       "      <td>0.6957</td>\n",
       "      <td>2.9745</td>\n",
       "      <td>-0.2098</td>\n",
       "      <td>1.1943</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Key</th>\n",
       "      <td>0.6957</td>\n",
       "      <td>2.9745</td>\n",
       "      <td>-0.2098</td>\n",
       "      <td>1.1943</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Value</th>\n",
       "      <td>0.6035</td>\n",
       "      <td>1.3980</td>\n",
       "      <td>-0.1532</td>\n",
       "      <td>0.7037</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final LayerNorm</th>\n",
       "      <td>0.3372</td>\n",
       "      <td>2.3340</td>\n",
       "      <td>-1.6596</td>\n",
       "      <td>2.8239</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Query</th>\n",
       "      <td>0.2561</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>-0.0941</td>\n",
       "      <td>0.3661</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rotary Q</th>\n",
       "      <td>0.2561</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>-0.0941</td>\n",
       "      <td>0.3661</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LN2 Scale</th>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.1591</td>\n",
       "      <td>-0.1336</td>\n",
       "      <td>0.1144</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LN1 Scale</th>\n",
       "      <td>-0.0278</td>\n",
       "      <td>0.0996</td>\n",
       "      <td>-0.1408</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Mean Improvement  Max Improvement  Min Improvement  \\\n",
       "Layer Type                                                                \n",
       "Residual Pre                   2.8819           4.8330           1.6056   \n",
       "Embedding                      2.8590           2.8590           2.8590   \n",
       "Residual Post                  2.7945           4.8330           1.6056   \n",
       "MLP Output                     1.5241           2.8103          -0.4041   \n",
       "Attention Output               1.0075           1.7497          -0.1208   \n",
       "Attention Z                    0.9517           1.9289          -0.1669   \n",
       "LN2 Normalized                 0.9408           2.2000          -0.3116   \n",
       "MLP Pre-activation             0.8776           2.6593          -1.0814   \n",
       "MLP Post-activation            0.8776           2.6593          -1.0814   \n",
       "LN1 Normalized                 0.8554           2.2963           0.1554   \n",
       "Rotary K                       0.6957           2.9745          -0.2098   \n",
       "Key                            0.6957           2.9745          -0.2098   \n",
       "Value                          0.6035           1.3980          -0.1532   \n",
       "Final LayerNorm                0.3372           2.3340          -1.6596   \n",
       "Query                          0.2561           0.8948          -0.0941   \n",
       "Rotary Q                       0.2561           0.8948          -0.0941   \n",
       "LN2 Scale                      0.0229           0.1591          -0.1336   \n",
       "LN1 Scale                     -0.0278           0.0996          -0.1408   \n",
       "\n",
       "                     Std Dev  Count  \n",
       "Layer Type                           \n",
       "Residual Pre          1.2509      6  \n",
       "Embedding                NaN      1  \n",
       "Residual Post         1.2710      6  \n",
       "MLP Output            1.3913      6  \n",
       "Attention Output      0.7800      6  \n",
       "Attention Z           0.8623      6  \n",
       "LN2 Normalized        0.9581      6  \n",
       "MLP Pre-activation    1.4632      6  \n",
       "MLP Post-activation   1.4632      6  \n",
       "LN1 Normalized        0.7943      6  \n",
       "Rotary K              1.1943      6  \n",
       "Key                   1.1943      6  \n",
       "Value                 0.7037      6  \n",
       "Final LayerNorm       2.8239      2  \n",
       "Query                 0.3661      6  \n",
       "Rotary Q              0.3661      6  \n",
       "LN2 Scale             0.1144      6  \n",
       "LN1 Scale             0.0940      6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Summary by Layer Number\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Improvement</th>\n",
       "      <th>Max Improvement</th>\n",
       "      <th>Min Improvement</th>\n",
       "      <th>Std Dev</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9827</td>\n",
       "      <td>2.8590</td>\n",
       "      <td>-0.2810</td>\n",
       "      <td>0.9333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7018</td>\n",
       "      <td>2.1050</td>\n",
       "      <td>-0.3116</td>\n",
       "      <td>0.8456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7351</td>\n",
       "      <td>2.9745</td>\n",
       "      <td>-1.0814</td>\n",
       "      <td>1.2669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2006</td>\n",
       "      <td>3.8870</td>\n",
       "      <td>-0.2093</td>\n",
       "      <td>1.2561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1312</td>\n",
       "      <td>4.8330</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>1.5089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9536</td>\n",
       "      <td>4.8330</td>\n",
       "      <td>-0.2098</td>\n",
       "      <td>1.5014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mean Improvement  Max Improvement  Min Improvement  Std Dev\n",
       "Layer Number                                                             \n",
       "0                       0.9827           2.8590          -0.2810   0.9333\n",
       "1                       0.7018           2.1050          -0.3116   0.8456\n",
       "2                       0.7351           2.9745          -1.0814   1.2669\n",
       "3                       1.2006           3.8870          -0.2093   1.2561\n",
       "4                       1.1312           4.8330           0.0094   1.5089\n",
       "5                       0.9536           4.8330          -0.2098   1.5014"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Analysis by Component Category\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Improvement</th>\n",
       "      <th>Max Improvement</th>\n",
       "      <th>Min Improvement</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Embedding</th>\n",
       "      <td>2.8590</td>\n",
       "      <td>2.8590</td>\n",
       "      <td>2.8590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual Stream</th>\n",
       "      <td>2.8382</td>\n",
       "      <td>4.8330</td>\n",
       "      <td>1.6056</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Components</th>\n",
       "      <td>1.0931</td>\n",
       "      <td>2.8103</td>\n",
       "      <td>-1.0814</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attention Components</th>\n",
       "      <td>0.6380</td>\n",
       "      <td>2.9745</td>\n",
       "      <td>-0.2098</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer Normalization</th>\n",
       "      <td>0.4393</td>\n",
       "      <td>2.3340</td>\n",
       "      <td>-1.6596</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Mean Improvement  Max Improvement  Min Improvement  \\\n",
       "Component Category                                                         \n",
       "Embedding                       2.8590           2.8590           2.8590   \n",
       "Residual Stream                 2.8382           4.8330           1.6056   \n",
       "MLP Components                  1.0931           2.8103          -1.0814   \n",
       "Attention Components            0.6380           2.9745          -0.2098   \n",
       "Layer Normalization             0.4393           2.3340          -1.6596   \n",
       "\n",
       "                      Count  \n",
       "Component Category           \n",
       "Embedding                 1  \n",
       "Residual Stream          12  \n",
       "MLP Components           18  \n",
       "Attention Components     42  \n",
       "Layer Normalization      26  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Best Layer in Each Major Category\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component Category</th>\n",
       "      <th>Layer</th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Log Prob Improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Residual Stream</td>\n",
       "      <td>blocks.5.hook_resid_pre</td>\n",
       "      <td>Residual Pre</td>\n",
       "      <td>4.832985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Attention Components</td>\n",
       "      <td>blocks.2.attn.hook_k</td>\n",
       "      <td>Key</td>\n",
       "      <td>2.974463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Embedding</td>\n",
       "      <td>hook_embed</td>\n",
       "      <td>Embedding</td>\n",
       "      <td>2.858965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>MLP Components</td>\n",
       "      <td>blocks.3.hook_mlp_out</td>\n",
       "      <td>MLP Output</td>\n",
       "      <td>2.810335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Layer Normalization</td>\n",
       "      <td>ln_final.hook_normalized</td>\n",
       "      <td>Final LayerNorm</td>\n",
       "      <td>2.334048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Component Category                     Layer       Layer Type  \\\n",
       "81       Residual Stream   blocks.5.hook_resid_pre     Residual Pre   \n",
       "37  Attention Components      blocks.2.attn.hook_k              Key   \n",
       "0              Embedding                hook_embed        Embedding   \n",
       "63        MLP Components     blocks.3.hook_mlp_out       MLP Output   \n",
       "98   Layer Normalization  ln_final.hook_normalized  Final LayerNorm   \n",
       "\n",
       "    Log Prob Improvement  \n",
       "81              4.832985  \n",
       "37              2.974463  \n",
       "0               2.858965  \n",
       "63              2.810335  \n",
       "98              2.334048  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Detailed Attention Component Analysis\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attention Output</th>\n",
       "      <td>1.0075</td>\n",
       "      <td>1.7497</td>\n",
       "      <td>-0.1208</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attention Z</th>\n",
       "      <td>0.9517</td>\n",
       "      <td>1.9289</td>\n",
       "      <td>-0.1669</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Key</th>\n",
       "      <td>0.6957</td>\n",
       "      <td>2.9745</td>\n",
       "      <td>-0.2098</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rotary K</th>\n",
       "      <td>0.6957</td>\n",
       "      <td>2.9745</td>\n",
       "      <td>-0.2098</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Value</th>\n",
       "      <td>0.6035</td>\n",
       "      <td>1.3980</td>\n",
       "      <td>-0.1532</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Query</th>\n",
       "      <td>0.2561</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>-0.0941</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rotary Q</th>\n",
       "      <td>0.2561</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>-0.0941</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean     Max     Min  Count\n",
       "Layer Type                                     \n",
       "Attention Output  1.0075  1.7497 -0.1208      6\n",
       "Attention Z       0.9517  1.9289 -0.1669      6\n",
       "Key               0.6957  2.9745 -0.2098      6\n",
       "Rotary K          0.6957  2.9745 -0.2098      6\n",
       "Value             0.6035  1.3980 -0.1532      6\n",
       "Query             0.2561  0.8948 -0.0941      6\n",
       "Rotary Q          0.2561  0.8948 -0.0941      6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Detailed MLP Component Analysis\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLP Output</th>\n",
       "      <td>1.5241</td>\n",
       "      <td>2.8103</td>\n",
       "      <td>-0.4041</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Post-activation</th>\n",
       "      <td>0.8776</td>\n",
       "      <td>2.6593</td>\n",
       "      <td>-1.0814</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Pre-activation</th>\n",
       "      <td>0.8776</td>\n",
       "      <td>2.6593</td>\n",
       "      <td>-1.0814</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Mean     Max     Min  Count\n",
       "Layer Type                                        \n",
       "MLP Output           1.5241  2.8103 -0.4041      6\n",
       "MLP Post-activation  0.8776  2.6593 -1.0814      6\n",
       "MLP Pre-activation   0.8776  2.6593 -1.0814      6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Best Component in Each Transformer Block\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Number</th>\n",
       "      <th>Layer</th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Log Prob Improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>blocks.0.hook_resid_pre</td>\n",
       "      <td>Residual Pre</td>\n",
       "      <td>2.858965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>blocks.1.hook_resid_post</td>\n",
       "      <td>Residual Post</td>\n",
       "      <td>2.104969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>blocks.2.attn.hook_k</td>\n",
       "      <td>Key</td>\n",
       "      <td>2.974463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3</td>\n",
       "      <td>blocks.3.hook_resid_post</td>\n",
       "      <td>Residual Post</td>\n",
       "      <td>3.886961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>4</td>\n",
       "      <td>blocks.4.hook_resid_post</td>\n",
       "      <td>Residual Post</td>\n",
       "      <td>4.832985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>5</td>\n",
       "      <td>blocks.5.hook_resid_pre</td>\n",
       "      <td>Residual Pre</td>\n",
       "      <td>4.832985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Layer Number                     Layer     Layer Type  \\\n",
       "1              0   blocks.0.hook_resid_pre   Residual Pre   \n",
       "32             1  blocks.1.hook_resid_post  Residual Post   \n",
       "37             2      blocks.2.attn.hook_k            Key   \n",
       "64             3  blocks.3.hook_resid_post  Residual Post   \n",
       "80             4  blocks.4.hook_resid_post  Residual Post   \n",
       "81             5   blocks.5.hook_resid_pre   Residual Pre   \n",
       "\n",
       "    Log Prob Improvement  \n",
       "1               2.858965  \n",
       "32              2.104969  \n",
       "37              2.974463  \n",
       "64              3.886961  \n",
       "80              4.832985  \n",
       "81              4.832985  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Activation patching with per-step caching using run_with_hooks\n",
    "# For each token prediction, get fresh cache from target model so shapes always match\n",
    "\n",
    "def make_patch_fn(layer_name, cache_to_use):\n",
    "    \"\"\"Simple patching function - assumes cache matches current sequence length\"\"\"\n",
    "    def patch_fn(activation, hook):\n",
    "        if hook.name == layer_name:\n",
    "            return cache_to_use[layer_name]\n",
    "        return activation\n",
    "    return patch_fn\n",
    "\n",
    "def calculate_target_pii_probability_with_patching(control_model, target_model, tokens, target_pii, layer_to_patch):\n",
    "    \"\"\"\n",
    "    Calculate log probability while patching a specific layer.\n",
    "    Re-caches target activations at each step to avoid shape mismatches.\n",
    "    \n",
    "    Args:\n",
    "        control_model: Control model to evaluate\n",
    "        target_model: Target model to get activations from\n",
    "        tokens: Input tokens\n",
    "        target_pii: Expected PII string\n",
    "        layer_to_patch: Which layer to patch\n",
    "    \n",
    "    Returns:\n",
    "        token_log_probs: List of log probabilities for each target token\n",
    "        sequence_log_prob: Sum of log probabilities\n",
    "    \"\"\"\n",
    "    # Tokenize target PII\n",
    "    target_pii_tokens = control_model.to_tokens(target_pii, prepend_bos=False)[0]\n",
    "    target_token_ids = target_pii_tokens.tolist()\n",
    "    \n",
    "    current_tokens = tokens.clone()\n",
    "    token_log_probs = []\n",
    "    \n",
    "    for i, target_token_id in enumerate(target_token_ids):\n",
    "        # Get cache from target model for current sequence length\n",
    "        _, target_cache = target_model.run_with_cache(current_tokens)\n",
    "        \n",
    "        # Run control model with patching hook\n",
    "        logits = control_model.run_with_hooks(\n",
    "            current_tokens,\n",
    "            fwd_hooks=[(layer_to_patch, make_patch_fn(layer_to_patch, target_cache))],\n",
    "            return_type='logits'\n",
    "        )\n",
    "        \n",
    "        last_token_logits = logits[0, -1, :]\n",
    "        log_probs = torch.log_softmax(last_token_logits, dim=-1)\n",
    "        \n",
    "        # Get log probability of the TARGET token\n",
    "        target_log_prob = log_probs[target_token_id].item()\n",
    "        token_log_probs.append(target_log_prob)\n",
    "        \n",
    "        # Append TARGET token to sequence for next iteration (teacher forcing)\n",
    "        current_tokens = torch.cat([current_tokens, torch.tensor([[target_token_id]], device=current_tokens.device)], dim=1)\n",
    "    \n",
    "    # Calculate sequence log probability\n",
    "    sequence_log_prob = sum(token_log_probs)\n",
    "    \n",
    "    return token_log_probs, sequence_log_prob\n",
    "\n",
    "def extract_layer_type(layer_name):\n",
    "    \"\"\"Extract the type of layer from its name\"\"\"\n",
    "    if 'hook_embed' in layer_name:\n",
    "        return 'Embedding'\n",
    "    elif 'ln_final' in layer_name:\n",
    "        return 'Final LayerNorm'\n",
    "    elif 'hook_resid_pre' in layer_name:\n",
    "        return 'Residual Pre'\n",
    "    elif 'hook_resid_post' in layer_name:\n",
    "        return 'Residual Post'\n",
    "    elif 'hook_attn_out' in layer_name:\n",
    "        return 'Attention Output'\n",
    "    elif 'hook_mlp_out' in layer_name:\n",
    "        return 'MLP Output'\n",
    "    elif 'ln1.hook_normalized' in layer_name:\n",
    "        return 'LN1 Normalized'\n",
    "    elif 'ln1.hook_scale' in layer_name:\n",
    "        return 'LN1 Scale'\n",
    "    elif 'ln2.hook_normalized' in layer_name:\n",
    "        return 'LN2 Normalized'\n",
    "    elif 'ln2.hook_scale' in layer_name:\n",
    "        return 'LN2 Scale'\n",
    "    elif 'mlp.hook_pre' in layer_name:\n",
    "        return 'MLP Pre-activation'\n",
    "    elif 'mlp.hook_post' in layer_name:\n",
    "        return 'MLP Post-activation'\n",
    "    elif 'hook_q' in layer_name:\n",
    "        return 'Query'\n",
    "    elif 'hook_k' in layer_name:\n",
    "        return 'Key'\n",
    "    elif 'hook_v' in layer_name:\n",
    "        return 'Value'\n",
    "    elif 'hook_z' in layer_name:\n",
    "        return 'Attention Z'\n",
    "    elif 'hook_attn_scores' in layer_name:\n",
    "        return 'Attention Scores'\n",
    "    elif 'hook_pattern' in layer_name:\n",
    "        return 'Attention Pattern'\n",
    "    elif 'hook_rot_q' in layer_name:\n",
    "        return 'Rotary Q'\n",
    "    elif 'hook_rot_k' in layer_name:\n",
    "        return 'Rotary K'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "all_layers = list(target_cache.keys())\n",
    "\n",
    "# Test all layers (excluding LayerNorm for speed)\n",
    "layers_to_test = [layer for layer in all_layers if '.ln' not in layer and 'ln_final' not in layer]\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(\"Activation Patching Analysis (Per-Step Caching)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Testing {len(layers_to_test)} layers\")\n",
    "print(f\"Baseline - Control model log prob: {control_seq_log_prob:.4f}\")\n",
    "print(f\"Target model log prob: {target_seq_log_prob:.4f}\")\n",
    "print(f\"Expected PII: '{expected_pii}'\")\n",
    "print(f\"\\nNote: Re-caches at each token prediction for accurate patching\")\n",
    "print(f\"\\n\")\n",
    "\n",
    "patching_results = []\n",
    "\n",
    "for i, layer_name in enumerate(layers_to_test):\n",
    "    # Calculate probability with patching (re-caches at each step)\n",
    "    patched_token_log_probs, patched_seq_log_prob = calculate_target_pii_probability_with_patching(\n",
    "        tl_control_model, tl_target_model, tokens, expected_pii, layer_name\n",
    "    )\n",
    "    \n",
    "    # Calculate improvement\n",
    "    log_prob_improvement = patched_seq_log_prob - control_seq_log_prob\n",
    "    \n",
    "    # Extract layer info\n",
    "    layer_type = extract_layer_type(layer_name)\n",
    "    layer_num = int(layer_name.split('.')[1]) if 'blocks.' in layer_name else -1\n",
    "    \n",
    "    patching_results.append({\n",
    "        'Layer': layer_name,\n",
    "        'Layer Type': layer_type,\n",
    "        'Layer Number': layer_num,\n",
    "        'Log Prob Improvement': log_prob_improvement,\n",
    "        'Patched Log Prob': patched_seq_log_prob\n",
    "    })\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Processed {i + 1}/{len(layers_to_test)} layers...\")\n",
    "\n",
    "print(f\"\\nCompleted testing {len(layers_to_test)} layers!\")\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame(patching_results)\n",
    "results_df = results_df.sort_values('Log Prob Improvement', ascending=False)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Top 15 Layers by Log Prob Improvement\")\n",
    "print(f\"{'='*60}\")\n",
    "display(results_df[['Layer', 'Layer Type', 'Log Prob Improvement']].head(15))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Summary by Layer Type\")\n",
    "print(f\"{'='*60}\")\n",
    "type_summary = results_df.groupby('Layer Type')['Log Prob Improvement'].agg(['mean', 'max', 'min', 'count']).round(4)\n",
    "type_summary.columns = ['Mean', 'Max', 'Min', 'Count']\n",
    "type_summary = type_summary.sort_values('Mean', ascending=False)\n",
    "display(type_summary)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Summary by Layer Number\")\n",
    "print(f\"{'='*60}\")\n",
    "layer_summary = results_df[results_df['Layer Number'] >= 0].groupby('Layer Number')['Log Prob Improvement'].agg(['mean', 'max']).round(4)\n",
    "layer_summary.columns = ['Mean', 'Max']\n",
    "display(layer_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pii_memo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
